{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "In this notebook, we illustrate how to use the Neural News Recommendation with Multi-Head Self-Attention ([NRMS](https://aclanthology.org/D19-1671/)). The implementation is taken from the [recommenders](https://github.com/recommenders-team/recommenders) repository. We have simply stripped the model to keep it cleaner.\n",
    "\n",
    "We use a small dataset, which is downloaded from [recsys.eb.dk](https://recsys.eb.dk/). All the datasets are stored in the folder path ```~/ebnerd_data/*```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\antot\\miniconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "import datetime\n",
    "\n",
    "from ebrec.utils._constants import *\n",
    "\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    "    ebnerd_from_path,\n",
    ")\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import NRMSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"Available devices:\", physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels\n",
    "We sample a few just to get started. For testset we just make up a dummy column with 0 and 1 - this is not the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = Path(\"~/ebnerd_data\").expanduser()\n",
    "# #\n",
    "# DATASPLIT = \"ebnerd_small\"\n",
    "# DUMP_DIR = Path(\"ebnerd_predictions\")\n",
    "# DUMP_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Use raw string to avoid issues with backslashes\n",
    "PATH = Path(r\"C:\\Users\\antot\\Downloads\\ebnerd-benchmark\\examples\\ebnerd_data\").expanduser()\n",
    "TRAIN = f\"ebnerd_small\"  # [ebnerd_demo, ebnerd_small, ebnerd_large]\n",
    "VAL = f\"ebnerd_small\"\n",
    "TEST = f\"ebnerd_testset\"#, \"ebnerd_testset_gt\"\n",
    "\n",
    "\n",
    "# Create a directory for dumping predictions\n",
    "#DUMP_DIR = Path(\"ebnerd_predictions\")\n",
    "#DUMP_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMP_DIR = Path(r\"C:\\Users\\antot\\Downloads\\ebnerd-benchmark\\examples\").expanduser()\n",
    "DUMP_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History size can often be a memory bottleneck; if adjusted, the NRMS hyperparameter ```history_size``` must be updated to ensure compatibility and efficient memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_SIZE = 20\n",
    "hparams_nrms.history_size = HISTORY_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We just want to load the necessary columns\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "# This notebook is just a simple 'get-started'; we down sample the number of samples to just run quickly through it.\n",
    "FRACTION = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we sample the dataset, just to keep it smaller. We'll split the training data into training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 234277\n",
      "Validation samples: 246289\n",
      "Train Data Sample:\n",
      "shape: (2, 7)\n",
      "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
      "│ user_id ┆ impression_i ┆ impression_t ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ labels      │\n",
      "│ ---     ┆ d            ┆ ime          ┆ ixed         ┆ clicked      ┆ inview       ┆ ---         │\n",
      "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
      "│         ┆ u32          ┆ datetime[μs] ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆             │\n",
      "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
      "│ 139836  ┆ 149474       ┆ 2023-05-24   ┆ [0, 9745590, ┆ [9778657]    ┆ [9778728,    ┆ [0, 0, … 1] │\n",
      "│         ┆              ┆ 07:47:53     ┆ … 9765156]   ┆              ┆ 9778669, …   ┆             │\n",
      "│         ┆              ┆              ┆              ┆              ┆ 9778657]     ┆             │\n",
      "│ 143471  ┆ 150528       ┆ 2023-05-24   ┆ [9767637,    ┆ [9778623]    ┆ [9778669,    ┆ [0, 0, … 1] │\n",
      "│         ┆              ┆ 07:33:25     ┆ 9769414, …   ┆              ┆ 9778682, …   ┆             │\n",
      "│         ┆              ┆              ┆ 9770989]     ┆              ┆ 9778623]     ┆             │\n",
      "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘\n",
      "Validation Data Sample:\n",
      "shape: (2, 7)\n",
      "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
      "│ user_id ┆ impression_i ┆ impression_t ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ labels      │\n",
      "│ ---     ┆ d            ┆ ime          ┆ ixed         ┆ clicked      ┆ inview       ┆ ---         │\n",
      "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
      "│         ┆ u32          ┆ datetime[μs] ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆             │\n",
      "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
      "│ 22548   ┆ 96791        ┆ 2023-05-28   ┆ [9773295,    ┆ [9784696]    ┆ [9784710,    ┆ [0, 0, … 1] │\n",
      "│         ┆              ┆ 04:21:24     ┆ 9769504, …   ┆              ┆ 9784591, …   ┆             │\n",
      "│         ┆              ┆              ┆ 9776929]     ┆              ┆ 9784696]     ┆             │\n",
      "│ 22548   ┆ 96798        ┆ 2023-05-28   ┆ [9773295,    ┆ [9784281]    ┆ [9782656,    ┆ [0, 0, … 1] │\n",
      "│         ┆              ┆ 04:31:48     ┆ 9769504, …   ┆              ┆ 9783405, …   ┆             │\n",
      "│         ┆              ┆              ┆ 9776929]     ┆              ┆ 9784281]     ┆             │\n",
      "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Load your train and validation datasets directly\n",
    "df_train = ebnerd_from_path(\n",
    "    PATH.joinpath(\"ebnerd_small/train\"),\n",
    "    history_size=HISTORY_SIZE,\n",
    "    \n",
    ").select(COLUMNS).pipe(\n",
    "    sampling_strategy_wu2019,\n",
    "    npratio=4,\n",
    "    shuffle=True,\n",
    "    with_replacement=True,\n",
    "    seed=123,\n",
    ").pipe(create_binary_labels_column)\n",
    "\n",
    "df_validation = ebnerd_from_path(\n",
    "    PATH.joinpath(\"ebnerd_small/validation\"),\n",
    "    history_size=HISTORY_SIZE\n",
    "    \n",
    ").select(COLUMNS).pipe(\n",
    "    sampling_strategy_wu2019,\n",
    "    npratio=4,\n",
    "    shuffle=True,\n",
    "    with_replacement=True,\n",
    "    seed=123,\n",
    ").pipe(create_binary_labels_column)\n",
    "\n",
    "print(f\"Train samples: {df_train.height}\\nValidation samples: {df_validation.height}\")\n",
    "\n",
    "# Preview the datasets\n",
    "print(\"Train Data Sample:\")\n",
    "print(df_train.head(2))\n",
    "\n",
    "print(\"Validation Data Sample:\")\n",
    "print(df_validation.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(f\"Model Directory: {MODEL_NAME}\")\n",
    "\n",
    "# Data preprocessing parameters\n",
    "MAX_TITLE_LENGTH = 30\n",
    "HISTORY_SIZE = 20\n",
    "FRACTION = 1.0\n",
    "EPOCHS = 5\n",
    "FRACTION_TEST = 1.0\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "\n",
    "# Batch sizes\n",
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_VAL = 64\n",
    "BATCH_SIZE_TEST_WO_B = 64\n",
    "BATCH_SIZE_TEST_W_B = 64\n",
    "N_CHUNKS_TEST = 10\n",
    "CHUNKS_DONE = 0\n",
    "\n",
    "# We just want to load the necessary columns\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "# This notebook is just a simple 'get-started'; we down sample the number of samples to just run quickly through it.\n",
    "FRACTION = 0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set\n",
    "We'll use the validation set, as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 135367\n",
      "Test Data Sample:\n",
      "shape: (2, 15)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ impressio ┆ impressio ┆ read_time ┆ scroll_pe ┆ … ┆ is_subscr ┆ session_i ┆ is_beyond ┆ article_ │\n",
      "│ n_id      ┆ n_time    ┆ ---       ┆ rcentage  ┆   ┆ iber      ┆ d         ┆ _accuracy ┆ id_fixed │\n",
      "│ ---       ┆ ---       ┆ f32       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│ u32       ┆ datetime[ ┆           ┆ f32       ┆   ┆ bool      ┆ u32       ┆ bool      ┆ list[i32 │\n",
      "│           ┆ μs]       ┆           ┆           ┆   ┆           ┆           ┆           ┆ ]        │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 210091342 ┆ 2023-06-0 ┆ 11.0      ┆ null      ┆ … ┆ false     ┆ 55445808  ┆ false     ┆ [9786066 │\n",
      "│           ┆ 8         ┆           ┆           ┆   ┆           ┆           ┆           ┆ ,        │\n",
      "│           ┆ 05:32:53  ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9785017, │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9789704] │\n",
      "│ 442219366 ┆ 2023-06-0 ┆ 13.0      ┆ null      ┆ … ┆ false     ┆ 79488948  ┆ false     ┆ [9788323 │\n",
      "│           ┆ 3         ┆           ┆           ┆   ┆           ┆           ┆           ┆ ,        │\n",
      "│           ┆ 05:18:50  ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9788145, │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9789710] │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "df_test = (\n",
    "    ebnerd_from_path(\n",
    "        PATH.joinpath(PATH, \"ebnerd_testset/test\")\n",
    "    )\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "print(f\"Test samples: {df_test.height}\")\n",
    "print(\"Test Data Sample:\")\n",
    "print(df_test.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNSTEST = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_LABELS_COL\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var i…</td><td>&quot;Politiet frygt…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den ø…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars …</td><td>&quot;Biografgængern…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har …</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun f…</td><td>&quot;FODBOLD: Morte…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem …</td><td>2006-05-01 14:28:40</td><td>[3177953]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8241</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytte…</td><td>&quot;I landets tynd…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erh…</td><td>2007-03-24 08:27:59</td><td>[3184029]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7053</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvor…</td><td>&quot;En flirtende s…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af o…</td><td>2007-01-18 10:30:37</td><td>[3030463]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9307</td><td>&quot;Neutral&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natascha… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind for…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret med ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ kE        ┆ …         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ områ…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flotte …  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_articles_train = pl.read_parquet(PATH.joinpath(\"ebnerd_small/articles.parquet\"))\n",
    "df_articles_train.head()\n",
    "#df_articles_test = pl.read_parquet(TEST_MAIN_PATH.joinpath(\"articles.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3000022</td><td>&quot;Hanks beskyldt…</td><td>&quot;Tom Hanks har …</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;Tom Hanks skul…</td><td>2006-09-20 09:24:18</td><td>[3518381]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;David Gardner&quot;]</td><td>[&quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Litteratur&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9911</td><td>&quot;Negative&quot;</td></tr><tr><td>3000063</td><td>&quot;Bostrups aske …</td><td>&quot;Studieværten b…</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;Strålende sens…</td><td>2006-09-24 07:45:30</td><td>[3170935, 3170939]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Underholdning&quot;, … &quot;Personlig begivenhed&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.5155</td><td>&quot;Neutral&quot;</td></tr><tr><td>3000613</td><td>&quot;Jesper Olsen r…</td><td>&quot;Den tidligere …</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Jesper Olsen, …</td><td>2006-05-09 11:29:00</td><td>[3164998]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;Frankrig&quot;, &quot;Jesper Olsen&quot;, … &quot;Jesper Olsen&quot;]</td><td>[&quot;LOC&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kendt&quot;, &quot;Sport&quot;, … &quot;Sygdom og behandling&quot;]</td><td>142</td><td>[196, 271]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9876</td><td>&quot;Negative&quot;</td></tr><tr><td>3000700</td><td>&quot;Madonna topløs…</td><td>&quot;47-årige Madon…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Skal du have s…</td><td>2006-05-04 11:03:12</td><td>[3172046]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Livsstil&quot;, &quot;Underholdning&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8786</td><td>&quot;Neutral&quot;</td></tr><tr><td>3000840</td><td>&quot;Otto Brandenbu…</td><td>&quot;Sangeren og sk…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;&#x27;Og lidt for S…</td><td>2007-03-01 18:34:00</td><td>[3914446]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Underholdning&quot;, … &quot;Musik og lyd&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9468</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3000022   ┆ Hanks     ┆ Tom Hanks ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9911    ┆ Negative │\n",
       "│           ┆ beskyldt  ┆ har angiv ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ for misha ┆ eligt     ┆ 06:20:32  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ ndling    ┆ mishand…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3000063   ┆ Bostrups  ┆ Studievær ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.5155    ┆ Neutral  │\n",
       "│           ┆ aske      ┆ ten blev  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ spredt i  ┆ mindet    ┆ 06:20:32  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Furesøen  ┆ med gla…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3000613   ┆ Jesper    ┆ Den       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9876    ┆ Negative │\n",
       "│           ┆ Olsen     ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ ramt af   ┆ danske    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ hjerneblø ┆ landshold ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ dn…       ┆ ss…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3000700   ┆ Madonna   ┆ 47-årige  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8786    ┆ Neutral  │\n",
       "│           ┆ topløs    ┆ Madonna   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ med heste ┆ poserer   ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ både to…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3000840   ┆ Otto Bran ┆ Sangeren  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9468    ┆ Negative │\n",
       "│           ┆ denburg   ┆ og skuesp ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er død    ┆ illeren   ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ Otto B…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles_test = pl.read_parquet(PATH.joinpath(PATH, \"ebnerd_testset/articles.parquet\"))\n",
    "df_articles_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face. \n",
    "Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antot\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles_train, cat_cal = concat_str_columns(df_articles_train, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles_train, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles_train, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping_train = create_article_id_to_value_mapping(\n",
    "    df=df_articles_train, value_col=token_col_title\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df_articles_test, cat_cal = concat_str_columns(df_articles_test, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles_test, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles_test, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping_test = create_article_id_to_value_mapping(\n",
    "    df=df_articles_test, value_col=token_col_title\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the dataloaders\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs.\n",
    "\n",
    "Note, with this ```NRMSDataLoader``` the ```eval_mode=False``` is meant for ```model.model.fit()``` whereas ```eval_mode=True``` is meant for ```model.scorer.predict()```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing train and validation dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Initialize DataLoaders for train and validation\n",
    "print(\"Initializing train and validation dataloaders...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8 # try with 64\n",
    "df_train_subset = df_train[:1000] \n",
    "df_val_subset = df_validation[:1000]  \n",
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train_subset,\n",
    "    article_dict=article_mapping_train,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_val_subset,\n",
    "    article_dict=article_mapping_train,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"Available devices:\", physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the NRMS-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\antot\\miniconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = NRMSModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "model.model.compile(\n",
    "    optimizer=model.model.optimizer,\n",
    "    loss=model.model.loss,\n",
    "    metrics=[\"AUC\"],\n",
    ")\n",
    "\n",
    "MODEL_NAME = model.__class__.__name__\n",
    "MODEL_WEIGHTS = DUMP_DIR.joinpath(f\"state_dict/{MODEL_NAME}/weights\")\n",
    "LOG_DIR = DUMP_DIR.joinpath(f\"runs/{MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "We will add some callbacks to model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define paths\n",
    "DUMP_DIR = Path(r\"C:\\Users\\antot\\Downloads\\ebnerd-benchmark\\examples\").expanduser()\n",
    "DUMP_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "MODEL_NAME = model.__class__.__name__\n",
    "MODEL_WEIGHTS = DUMP_DIR.joinpath(f\"state_dict/{MODEL_NAME}/weights\")\n",
    "LOG_DIR = DUMP_DIR.joinpath(f\"runs/{MODEL_NAME}\")\n",
    "\n",
    "# Ensure directory for weights exists\n",
    "MODEL_WEIGHTS.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Compile the model\n",
    "model = NRMSModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "model.model.compile(\n",
    "    optimizer=model.model.optimizer,\n",
    "    loss=model.model.loss,\n",
    "    metrics=[\"AUC\"],\n",
    ")\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=str(MODEL_WEIGHTS),\n",
    "    save_weights_only=True,\n",
    "    monitor='val_auc',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NRMSModel\n",
    "# MODEL_NAME = model.__class__.__name__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and store the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/1\n",
      "125/125 [==============================] - 261s 2s/step - loss: 3.3710 - auc: 0.5024 - val_loss: 4.2027 - val_auc: 0.5140 - lr: 1.0000e-04\n",
      "Epoch 1 completed in 261.31 seconds\n",
      "Model weights saved at: C:\\Users\\antot\\Downloads\\ebnerd-benchmark\\examples\\state_dict\\NRMSModel\\weights\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_auc\",  # Monitor validation AUC\n",
    "    mode=\"max\",         # Maximize AUC\n",
    "    factor=0.2,         # Reduce learning rate by 80%\n",
    "    patience=2,         # Wait for 2 epochs with no improvement\n",
    "    min_lr=1e-5         # Set a minimum learning rate\n",
    ")\n",
    "\n",
    "# Use callbacks if enabled\n",
    "USE_CALLBACKS = True\n",
    "callbacks = [lr_scheduler] if USE_CALLBACKS else []\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 1  # Adjust to desired number of epochs\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting Epoch {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "    # Train the model for one epoch\n",
    "    model.model.fit(\n",
    "        train_dataloader,              # Training data\n",
    "        validation_data=val_dataloader,  # Validation data\n",
    "        epochs=1,                       # One epoch at a time\n",
    "        callbacks=callbacks,            # Use callbacks if enabled\n",
    "        verbose=1                       # Display progress\n",
    "    )\n",
    "\n",
    "    # Measure epoch duration\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch + 1} completed in {epoch_time:.2f} seconds\")\n",
    "\n",
    "# Save weights after training\n",
    "MODEL_WEIGHTS.parent.mkdir(parents=True, exist_ok=True)  # Ensure directory exists\n",
    "model.model.save_weights(MODEL_WEIGHTS)\n",
    "print(f\"Model weights saved at: {MODEL_WEIGHTS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\antot\\miniconda3\\Lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:538: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if USE_CALLBACKS:\n",
    "    _ = model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example how to compute some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 135367\n",
      "Test Data Sample:\n",
      "shape: (2, 15)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ impressio ┆ impressio ┆ read_time ┆ scroll_pe ┆ … ┆ is_subscr ┆ session_i ┆ is_beyond ┆ article_ │\n",
      "│ n_id      ┆ n_time    ┆ ---       ┆ rcentage  ┆   ┆ iber      ┆ d         ┆ _accuracy ┆ id_fixed │\n",
      "│ ---       ┆ ---       ┆ f32       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│ u32       ┆ datetime[ ┆           ┆ f32       ┆   ┆ bool      ┆ u32       ┆ bool      ┆ list[i32 │\n",
      "│           ┆ μs]       ┆           ┆           ┆   ┆           ┆           ┆           ┆ ]        │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 508798591 ┆ 2023-06-0 ┆ 15.0      ┆ null      ┆ … ┆ false     ┆ 35722524  ┆ false     ┆ [9782438 │\n",
      "│           ┆ 1         ┆           ┆           ┆   ┆           ┆           ┆           ┆ ,        │\n",
      "│           ┆ 13:10:44  ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9782467, │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ …        │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9789910] │\n",
      "│ 49029812  ┆ 2023-06-0 ┆ 40.0      ┆ 100.0     ┆ … ┆ false     ┆ 85525980  ┆ false     ┆ [0, 0, … │\n",
      "│           ┆ 1         ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9790987] │\n",
      "│           ┆ 17:43:21  ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "df_test = (\n",
    "    ebnerd_from_path(\n",
    "        PATH.joinpath(PATH, \"ebnerd_testset/test\")\n",
    "    )\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "print(f\"Test samples: {df_test.height}\")\n",
    "print(\"Test Data Sample:\")\n",
    "print(df_test.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Αυτο  το χρηισμοποιεί αυτος δεν ειναι το δικό μας.... χρειαζεται ένα function το οποίο λογικα θα δημιουργεί μια κενο label column και μετα υπολογίζοντας τα σκορ να βαζει αυτό με το μεγαλύτερο να το κανει 1. Λογικα το γραφει κάπου στα utils η στους dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>impression_id</th><th>impression_time</th><th>article_id_fixed</th><th>article_ids_clicked</th><th>article_ids_inview</th><th>is_beyond_accuracy</th><th>labels</th></tr><tr><td>u32</td><td>u32</td><td>datetime[μs]</td><td>list[i32]</td><td>i32</td><td>list[i32]</td><td>bool</td><td>list[i32]</td></tr></thead><tbody><tr><td>35982</td><td>6451339</td><td>2023-06-05 15:02:49</td><td>[9786268, 9782806, … 9789494]</td><td>9796527</td><td>[9796527, 7851321, … 9492777]</td><td>false</td><td>[0, 0, … 0]</td></tr><tr><td>36012</td><td>6451363</td><td>2023-06-05 15:03:56</td><td>[9788323, 9788362, … 9790885]</td><td>9798532</td><td>[9798532, 9791602, … 9798958]</td><td>false</td><td>[0, 0, … 0]</td></tr><tr><td>36162</td><td>6451382</td><td>2023-06-05 15:25:53</td><td>[9788524, 9788106, … 9790700]</td><td>9798498</td><td>[9798498, 9793856, … 9798724]</td><td>false</td><td>[0, 0, … 0]</td></tr><tr><td>36162</td><td>6451383</td><td>2023-06-05 15:26:35</td><td>[9788524, 9788106, … 9790700]</td><td>9797419</td><td>[9797419, 9798829, … 9798805]</td><td>false</td><td>[0, 0, … 0]</td></tr><tr><td>36162</td><td>6451385</td><td>2023-06-05 15:26:14</td><td>[9788524, 9788106, … 9790700]</td><td>9785014</td><td>[9785014, 9798958, … 9486080]</td><td>false</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌─────────┬────────────┬────────────┬────────────┬────────────┬────────────┬───────────┬───────────┐\n",
       "│ user_id ┆ impression ┆ impression ┆ article_id ┆ article_id ┆ article_id ┆ is_beyond ┆ labels    │\n",
       "│ ---     ┆ _id        ┆ _time      ┆ _fixed     ┆ s_clicked  ┆ s_inview   ┆ _accuracy ┆ ---       │\n",
       "│ u32     ┆ ---        ┆ ---        ┆ ---        ┆ ---        ┆ ---        ┆ ---       ┆ list[i32] │\n",
       "│         ┆ u32        ┆ datetime[μ ┆ list[i32]  ┆ i32        ┆ list[i32]  ┆ bool      ┆           │\n",
       "│         ┆            ┆ s]         ┆            ┆            ┆            ┆           ┆           │\n",
       "╞═════════╪════════════╪════════════╪════════════╪════════════╪════════════╪═══════════╪═══════════╡\n",
       "│ 35982   ┆ 6451339    ┆ 2023-06-05 ┆ [9786268,  ┆ 9796527    ┆ [9796527,  ┆ false     ┆ [0, 0, …  │\n",
       "│         ┆            ┆ 15:02:49   ┆ 9782806, … ┆            ┆ 7851321, … ┆           ┆ 0]        │\n",
       "│         ┆            ┆            ┆ 9789494]   ┆            ┆ 9492777]   ┆           ┆           │\n",
       "│ 36012   ┆ 6451363    ┆ 2023-06-05 ┆ [9788323,  ┆ 9798532    ┆ [9798532,  ┆ false     ┆ [0, 0, …  │\n",
       "│         ┆            ┆ 15:03:56   ┆ 9788362, … ┆            ┆ 9791602, … ┆           ┆ 0]        │\n",
       "│         ┆            ┆            ┆ 9790885]   ┆            ┆ 9798958]   ┆           ┆           │\n",
       "│ 36162   ┆ 6451382    ┆ 2023-06-05 ┆ [9788524,  ┆ 9798498    ┆ [9798498,  ┆ false     ┆ [0, 0, …  │\n",
       "│         ┆            ┆ 15:25:53   ┆ 9788106, … ┆            ┆ 9793856, … ┆           ┆ 0]        │\n",
       "│         ┆            ┆            ┆ 9790700]   ┆            ┆ 9798724]   ┆           ┆           │\n",
       "│ 36162   ┆ 6451383    ┆ 2023-06-05 ┆ [9788524,  ┆ 9797419    ┆ [9797419,  ┆ false     ┆ [0, 0, …  │\n",
       "│         ┆            ┆ 15:26:35   ┆ 9788106, … ┆            ┆ 9798829, … ┆           ┆ 0]        │\n",
       "│         ┆            ┆            ┆ 9790700]   ┆            ┆ 9798805]   ┆           ┆           │\n",
       "│ 36162   ┆ 6451385    ┆ 2023-06-05 ┆ [9788524,  ┆ 9785014    ┆ [9785014,  ┆ false     ┆ [0, 0, …  │\n",
       "│         ┆            ┆ 15:26:14   ┆ 9788106, … ┆            ┆ 9798958, … ┆           ┆ 0]        │\n",
       "│         ┆            ┆            ┆ 9790700]   ┆            ┆ 9486080]   ┆           ┆           │\n",
       "└─────────┴────────────┴────────────┴────────────┴────────────┴────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"ebnerd_testset\", \"test\"), history_size=HISTORY_SIZE)\n",
    "    .sample(fraction=FRACTION_TEST)\n",
    "    .with_columns(\n",
    "        pl.col(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "        .list.first()\n",
    "        .alias(DEFAULT_CLICKED_ARTICLES_COL)\n",
    "    )\n",
    "    .select(COLUMNS + [DEFAULT_IS_BEYOND_ACCURACY_COL])\n",
    "    .with_columns(\n",
    "        pl.col(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "        .list.eval(pl.element() * 0)\n",
    "        .alias(DEFAULT_LABELS_COL)\n",
    "    )\n",
    ")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.count of shape: (13_536_710,)\n",
       "Series: 'is_beyond_accuracy' [bool]\n",
       "[\n",
       "\tfalse\n",
       "\tfalse\n",
       "\tfalse\n",
       "\tfalse\n",
       "\tfalse\n",
       "\tfalse\n",
       "\tfalse\n",
       "\tfalse\n",
       "\tfalse\n",
       "\tfalse\n",
       "\tfalse\n",
       "\tfalse\n",
       "\t…\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "\ttrue\n",
       "]>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"is_beyond_accuracy\"].count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Προσοχη το εόμενο είναι subset????????????????????????????///"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test= df_test[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I break it so that I can eun the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌────────────────────┬───────┐\n",
      "│ is_beyond_accuracy ┆ count │\n",
      "│ ---                ┆ ---   │\n",
      "│ bool               ┆ u32   │\n",
      "╞════════════════════╪═══════╡\n",
      "│ false              ┆ 500   │\n",
      "│ true               ┆ 500   │\n",
      "└────────────────────┴───────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antot\\AppData\\Local\\Temp\\ipykernel_21888\\4152766399.py:20: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  df_test.groupby(\"is_beyond_accuracy\")\n",
      "C:\\Users\\antot\\AppData\\Local\\Temp\\ipykernel_21888\\4152766399.py:21: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  .agg(pl.count().alias(\"count\"))\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Assume df_test is already defined\n",
    "df_test = df_test[:1000]  # Restrict to first 10,000 rows\n",
    "\n",
    "# Split 500 rows for each case\n",
    "df_false = df_test[:500].with_columns(\n",
    "    pl.lit(False).alias(\"is_beyond_accuracy\")\n",
    ")\n",
    "\n",
    "df_true = df_test[500:1000].with_columns(\n",
    "    pl.lit(True).alias(\"is_beyond_accuracy\")\n",
    ")\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "df_test = pl.concat([df_false, df_true])\n",
    "\n",
    "# Verify the distribution\n",
    "print(\n",
    "    df_test.groupby(\"is_beyond_accuracy\")\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows without beyond accuracy (False): 500\n",
      "Rows with beyond accuracy (True): 500\n"
     ]
    }
   ],
   "source": [
    "# Filter rows into two subsets\n",
    "df_test_wo_beyond = df_test.filter(~pl.col(\"is_beyond_accuracy\"))\n",
    "df_test_w_beyond = df_test.filter(pl.col(\"is_beyond_accuracy\"))\n",
    "\n",
    "# Verify the split\n",
    "print(\"Rows without beyond accuracy (False):\", df_test_wo_beyond.shape[0])\n",
    "print(\"Rows with beyond accuracy (True):\", df_test_w_beyond.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_w_beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebrec.utils._polars import split_df_chunks\n",
    "\n",
    "\n",
    "\n",
    "df_test_chunks = split_df_chunks(df_test_wo_beyond, n_chunks=N_CHUNKS_TEST)\n",
    "df_pred_test_wo_beyond = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN = 32\n",
    "BATCH_SIZE_VAL = 32\n",
    "BATCH_SIZE_TEST_WO_B = 32\n",
    "BATCH_SIZE_TEST_W_B = 4\n",
    "N_CHUNKS_TEST = 10\n",
    "CHUNKS_DONE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init test-dataloader: 1/10\n",
      "2/2 [==============================] - 6s 3s/step\n",
      "Init test-dataloader: 2/10\n",
      "2/2 [==============================] - 6s 2s/step\n",
      "Init test-dataloader: 3/10\n",
      "2/2 [==============================] - 6s 1s/step\n",
      "Init test-dataloader: 4/10\n",
      "2/2 [==============================] - 6s 2s/step\n",
      "Init test-dataloader: 5/10\n",
      "2/2 [==============================] - 6s 2s/step\n",
      "Init test-dataloader: 6/10\n",
      "2/2 [==============================] - 6s 2s/step\n",
      "Init test-dataloader: 7/10\n",
      "2/2 [==============================] - 5s 2s/step\n",
      "Init test-dataloader: 8/10\n",
      "2/2 [==============================] - 6s 2s/step\n",
      "Init test-dataloader: 9/10\n",
      "2/2 [==============================] - 5s 2s/step\n",
      "Init test-dataloader: 10/10\n",
      "2/2 [==============================] - 6s 2s/step\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from tensorflow.keras.backend import clear_session\n",
    "TEST_DF_DUMP = DUMP_DIR.joinpath(\"test_predictions\", MODEL_NAME)\n",
    "TEST_DF_DUMP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_test_chunks = split_df_chunks(df_test_wo_beyond, n_chunks=N_CHUNKS_TEST)\n",
    "df_pred_test_wo_beyond = []\n",
    "\n",
    "for i, df_test_chunk in enumerate(df_test_chunks[CHUNKS_DONE:], start=1 + CHUNKS_DONE):\n",
    "    print(f\"Init test-dataloader: {i}/{len(df_test_chunks)}\")\n",
    "    # Initialize DataLoader\n",
    "    test_dataloader_wo_b = NRMSDataLoader(\n",
    "        behaviors=df_test_chunk,\n",
    "        article_dict=article_mapping_test,\n",
    "        unknown_representation=\"zeros\",\n",
    "        history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "        eval_mode=True,\n",
    "        batch_size=BATCH_SIZE_TEST_WO_B,\n",
    "    )\n",
    "    # Predict and clear session\n",
    "    scores = model.scorer.predict(test_dataloader_wo_b)\n",
    "    clear_session()\n",
    "\n",
    "    # Process the predictions\n",
    "    df_test_chunk = add_prediction_scores(df_test_chunk, scores.tolist()).with_columns(\n",
    "        pl.col(\"scores\")\n",
    "        .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "        .alias(\"ranked_scores\")\n",
    "    )\n",
    "\n",
    "    # Save the processed chunk\n",
    "    df_test_chunk.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "        TEST_DF_DUMP.joinpath(f\"pred_wo_ba_{i}.parquet\")\n",
    "    )\n",
    "\n",
    "    # Append and clean up\n",
    "    df_pred_test_wo_beyond.append(df_test_chunk)\n",
    "\n",
    "    # Cleanup\n",
    "    del df_test_chunk, test_dataloader_wo_b, scores\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (30, 10)\n",
      "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ user_id ┆ impression ┆ impressio ┆ article_i ┆ … ┆ is_beyond ┆ labels    ┆ scores    ┆ ranked_sc │\n",
      "│ ---     ┆ _id        ┆ n_time    ┆ d_fixed   ┆   ┆ _accuracy ┆ ---       ┆ ---       ┆ ores      │\n",
      "│ u32     ┆ ---        ┆ ---       ┆ ---       ┆   ┆ ---       ┆ list[i32] ┆ list[f64] ┆ ---       │\n",
      "│         ┆ u32        ┆ datetime[ ┆ list[i32] ┆   ┆ bool      ┆           ┆           ┆ list[i64] │\n",
      "│         ┆            ┆ μs]       ┆           ┆   ┆           ┆           ┆           ┆           │\n",
      "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 35982   ┆ 6451339    ┆ 2023-06-0 ┆ [9786268, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.630941 ┆ [3, 2, …  │\n",
      "│         ┆            ┆ 5         ┆ 9782806,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 9]        │\n",
      "│         ┆            ┆ 15:02:49  ┆ …         ┆   ┆           ┆           ┆ 0.950646, ┆           │\n",
      "│         ┆            ┆           ┆ 9789494]  ┆   ┆           ┆           ┆ …         ┆           │\n",
      "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.008185] ┆           │\n",
      "│ 36012   ┆ 6451363    ┆ 2023-06-0 ┆ [9788323, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.104358 ┆ [4, 7, …  │\n",
      "│         ┆            ┆ 5         ┆ 9788362,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 3]        │\n",
      "│         ┆            ┆ 15:03:56  ┆ …         ┆   ┆           ┆           ┆ 0.001216, ┆           │\n",
      "│         ┆            ┆           ┆ 9790885]  ┆   ┆           ┆           ┆ …         ┆           │\n",
      "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.179523] ┆           │\n",
      "│ 36162   ┆ 6451382    ┆ 2023-06-0 ┆ [9788524, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.097785 ┆ [2, 5, …  │\n",
      "│         ┆            ┆ 5         ┆ 9788106,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 3]        │\n",
      "│         ┆            ┆ 15:25:53  ┆ …         ┆   ┆           ┆           ┆ 0.000392, ┆           │\n",
      "│         ┆            ┆           ┆ 9790700]  ┆   ┆           ┆           ┆ …         ┆           │\n",
      "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.015833] ┆           │\n",
      "│ 36162   ┆ 6451383    ┆ 2023-06-0 ┆ [9788524, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.024571 ┆ [9, 11, … │\n",
      "│         ┆            ┆ 5         ┆ 9788106,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 3]        │\n",
      "│         ┆            ┆ 15:26:35  ┆ …         ┆   ┆           ┆           ┆ 0.001634, ┆           │\n",
      "│         ┆            ┆           ┆ 9790700]  ┆   ┆           ┆           ┆ …         ┆           │\n",
      "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.580246] ┆           │\n",
      "│ 36162   ┆ 6451385    ┆ 2023-06-0 ┆ [9788524, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.918962 ┆ [2, 6, …  │\n",
      "│         ┆            ┆ 5         ┆ 9788106,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 1]        │\n",
      "│         ┆            ┆ 15:26:14  ┆ …         ┆   ┆           ┆           ┆ 0.120063, ┆           │\n",
      "│         ┆            ┆           ┆ 9790700]  ┆   ┆           ┆           ┆ … 0.9671] ┆           │\n",
      "│ …       ┆ …          ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
      "│ 36744   ┆ 6451546    ┆ 2023-06-0 ┆ [9756287, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.915963 ┆ [1, 3, …  │\n",
      "│         ┆            ┆ 5         ┆ 9787185,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 8]        │\n",
      "│         ┆            ┆ 15:16:22  ┆ …         ┆   ┆           ┆           ┆ 0.039178, ┆           │\n",
      "│         ┆            ┆           ┆ 9789832]  ┆   ┆           ┆           ┆ …         ┆           │\n",
      "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.001399] ┆           │\n",
      "│ 36744   ┆ 6451547    ┆ 2023-06-0 ┆ [9756287, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.003694 ┆ [3, 2, …  │\n",
      "│         ┆            ┆ 5         ┆ 9787185,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 1]        │\n",
      "│         ┆            ┆ 15:16:04  ┆ …         ┆   ┆           ┆           ┆ 0.285972, ┆           │\n",
      "│         ┆            ┆           ┆ 9789832]  ┆   ┆           ┆           ┆ … 0.6196] ┆           │\n",
      "│ 36744   ┆ 6451548    ┆ 2023-06-0 ┆ [9756287, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.629566 ┆ [2, 3, …  │\n",
      "│         ┆            ┆ 5         ┆ 9787185,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 5]        │\n",
      "│         ┆            ┆ 15:17:38  ┆ …         ┆   ┆           ┆           ┆ 0.010758, ┆           │\n",
      "│         ┆            ┆           ┆ 9789832]  ┆   ┆           ┆           ┆ …         ┆           │\n",
      "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.00061]  ┆           │\n",
      "│ 36768   ┆ 6451559    ┆ 2023-06-0 ┆ [9789461, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.860194 ┆ [4, 6, …  │\n",
      "│         ┆            ┆ 5         ┆ 9789404,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 2]        │\n",
      "│         ┆            ┆ 15:45:47  ┆ …         ┆   ┆           ┆           ┆ 0.049994, ┆           │\n",
      "│         ┆            ┆           ┆ 9789810]  ┆   ┆           ┆           ┆ …         ┆           │\n",
      "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.996662] ┆           │\n",
      "│ 36819   ┆ 6451578    ┆ 2023-06-0 ┆ [9778943, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.132396 ┆ [7, 8, …  │\n",
      "│         ┆            ┆ 5         ┆ 9780604,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 4]        │\n",
      "│         ┆            ┆ 15:43:03  ┆ …         ┆   ┆           ┆           ┆ 0.100575, ┆           │\n",
      "│         ┆            ┆           ┆ 9789417]  ┆   ┆           ┆           ┆ …         ┆           │\n",
      "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.75353]  ┆           │\n",
      "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Concatenate all DataFrame chunks into a single DataFrame\n",
    "df_pred_test_wo_beyond = pl.concat(df_pred_test_wo_beyond)\n",
    "\n",
    "# Now you can use the .select() method\n",
    "df_pred_test_wo_beyond.select(DEFAULT_IMPRESSION_ID_COL, \"scores\").write_parquet(\n",
    "    TEST_DF_DUMP.joinpath(\"pred_wo_ba.parquet\")\n",
    ")\n",
    "\n",
    "# View the head of the DataFrame\n",
    "print(df_pred_test_wo_beyond.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_w_beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_pred_test_wo_beyond))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ebrec.utils._constants import (\n",
    "#     DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "#     DEFAULT_IS_BEYOND_ACCURACY_COL,\n",
    "#     DEFAULT_CLICKED_ARTICLES_COL,\n",
    "#     DEFAULT_INVIEW_ARTICLES_COL,\n",
    "#     DEFAULT_IMPRESSION_ID_COL,\n",
    "#     DEFAULT_SUBTITLE_COL,\n",
    "#     DEFAULT_LABELS_COL,\n",
    "#     DEFAULT_TITLE_COL,\n",
    "#     DEFAULT_USER_COL,\n",
    "# )\n",
    "\n",
    "# # Prepare test data (without beyond-accuracy data)\n",
    "# # df_pred_test_wo_beyond = pl.concat(df_pred_test_wo_beyond)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred_test_wo_beyond.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "#     TEST_DF_DUMP.joinpath(\"pred_wo_ba.parquet\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init test-dataloader: beyond-accuracy\n"
     ]
    }
   ],
   "source": [
    "print(\"Init test-dataloader: beyond-accuracy\")\n",
    "test_dataloader_w_b = NRMSDataLoader(\n",
    "    behaviors=df_test_w_beyond,\n",
    "    article_dict=article_mapping_test,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=BATCH_SIZE_TEST_W_B,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 57s 457ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.scorer.predict(test_dataloader_w_b)\n",
    "df_pred_test_w_beyond = add_prediction_scores(\n",
    "    df_test_w_beyond, scores.tolist()\n",
    ").with_columns(\n",
    "    pl.col(\"scores\")\n",
    "    .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "    .alias(\"ranked_scores\")\n",
    ")\n",
    "df_pred_test_w_beyond.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "    TEST_DF_DUMP.joinpath(\"pred_w_ba.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of df_pred_test_wo_beyond:\n",
      "OrderedDict([('user_id', UInt32), ('impression_id', UInt32), ('impression_time', Datetime(time_unit='us', time_zone=None)), ('article_id_fixed', List(Int32)), ('article_ids_clicked', Int32), ('article_ids_inview', List(Int32)), ('is_beyond_accuracy', Boolean), ('labels', List(Int32)), ('scores', List(Float64)), ('ranked_scores', List(Int64))])\n",
      "Schema of df_pred_test_w_beyond:\n",
      "OrderedDict([('user_id', UInt32), ('impression_id', UInt32), ('impression_time', Datetime(time_unit='us', time_zone=None)), ('article_id_fixed', List(Int32)), ('article_ids_clicked', Int32), ('article_ids_inview', List(Int32)), ('is_beyond_accuracy', Boolean), ('labels', List(Int32)), ('scores', List(Float64)), ('ranked_scores', List(Int64))])\n"
     ]
    }
   ],
   "source": [
    "# Check the schemas of both DataFrames\n",
    "print(\"Schema of df_pred_test_wo_beyond:\")\n",
    "print(df_pred_test_wo_beyond.schema)\n",
    "\n",
    "print(\"Schema of df_pred_test_w_beyond:\")\n",
    "print(df_pred_test_w_beyond.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of df_pred_test_wo_beyond:\n",
      "OrderedDict([('user_id', UInt32), ('impression_id', UInt32), ('impression_time', Datetime(time_unit='us', time_zone=None)), ('article_id_fixed', List(Int32)), ('article_ids_clicked', Int32), ('article_ids_inview', List(Int32)), ('is_beyond_accuracy', Boolean), ('labels', List(Int32)), ('scores', List(Float64)), ('ranked_scores', List(Int64))])\n",
      "Schema of df_pred_test_w_beyond:\n",
      "OrderedDict([('user_id', UInt32), ('impression_id', UInt32), ('impression_time', Datetime(time_unit='us', time_zone=None)), ('article_id_fixed', List(Int32)), ('article_ids_clicked', Int32), ('article_ids_inview', List(Int32)), ('is_beyond_accuracy', Boolean), ('labels', List(Int32)), ('scores', List(Float64)), ('ranked_scores', List(Int64))])\n"
     ]
    }
   ],
   "source": [
    "# Check the schemas of both DataFrames\n",
    "print(\"Schema of df_pred_test_wo_beyond:\")\n",
    "print(df_pred_test_wo_beyond.schema)\n",
    "\n",
    "print(\"Schema of df_pred_test_w_beyond:\")\n",
    "print(df_pred_test_w_beyond.schema)\n",
    "\n",
    "# Align column types\n",
    "df_pred_test_wo_beyond = df_pred_test_wo_beyond.with_columns(\n",
    "    [pl.col(column).cast(df_pred_test_w_beyond.schema[column]) for column in df_pred_test_w_beyond.schema]\n",
    ")\n",
    "\n",
    "# Combine both DataFrames\n",
    "df_test = pl.concat([df_pred_test_wo_beyond, df_pred_test_w_beyond])\n",
    "\n",
    "# Write to Parquet\n",
    "df_test.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "    TEST_DF_DUMP.joinpath(\"pred_concat.parquet\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'polars.dataframe.frame.DataFrame'>\n",
      "<class 'polars.dataframe.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_pred_test_wo_beyond))\n",
    "print(type(df_pred_test_w_beyond))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.head of shape: (1_000, 10)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ user_id ┆ impression ┆ impressio ┆ article_i ┆ … ┆ is_beyond ┆ labels    ┆ scores    ┆ ranked_sc │\n",
       "│ ---     ┆ _id        ┆ n_time    ┆ d_fixed   ┆   ┆ _accuracy ┆ ---       ┆ ---       ┆ ores      │\n",
       "│ u32     ┆ ---        ┆ ---       ┆ ---       ┆   ┆ ---       ┆ list[i32] ┆ list[f64] ┆ ---       │\n",
       "│         ┆ u32        ┆ datetime[ ┆ list[i32] ┆   ┆ bool      ┆           ┆           ┆ list[i64] │\n",
       "│         ┆            ┆ μs]       ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 35982   ┆ 6451339    ┆ 2023-06-0 ┆ [9786268, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.630941 ┆ [3, 2, …  │\n",
       "│         ┆            ┆ 5         ┆ 9782806,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 9]        │\n",
       "│         ┆            ┆ 15:02:49  ┆ …         ┆   ┆           ┆           ┆ 0.950646, ┆           │\n",
       "│         ┆            ┆           ┆ 9789494]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.008185] ┆           │\n",
       "│ 36012   ┆ 6451363    ┆ 2023-06-0 ┆ [9788323, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.104358 ┆ [4, 7, …  │\n",
       "│         ┆            ┆ 5         ┆ 9788362,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 3]        │\n",
       "│         ┆            ┆ 15:03:56  ┆ …         ┆   ┆           ┆           ┆ 0.001216, ┆           │\n",
       "│         ┆            ┆           ┆ 9790885]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.179523] ┆           │\n",
       "│ 36162   ┆ 6451382    ┆ 2023-06-0 ┆ [9788524, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.097785 ┆ [2, 5, …  │\n",
       "│         ┆            ┆ 5         ┆ 9788106,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 3]        │\n",
       "│         ┆            ┆ 15:25:53  ┆ …         ┆   ┆           ┆           ┆ 0.000392, ┆           │\n",
       "│         ┆            ┆           ┆ 9790700]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.015833] ┆           │\n",
       "│ 36162   ┆ 6451383    ┆ 2023-06-0 ┆ [9788524, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.024571 ┆ [9, 11, … │\n",
       "│         ┆            ┆ 5         ┆ 9788106,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 3]        │\n",
       "│         ┆            ┆ 15:26:35  ┆ …         ┆   ┆           ┆           ┆ 0.001634, ┆           │\n",
       "│         ┆            ┆           ┆ 9790700]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.580246] ┆           │\n",
       "│ 36162   ┆ 6451385    ┆ 2023-06-0 ┆ [9788524, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.918962 ┆ [2, 6, …  │\n",
       "│         ┆            ┆ 5         ┆ 9788106,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 1]        │\n",
       "│         ┆            ┆ 15:26:14  ┆ …         ┆   ┆           ┆           ┆ 0.120063, ┆           │\n",
       "│         ┆            ┆           ┆ 9790700]  ┆   ┆           ┆           ┆ … 0.9671] ┆           │\n",
       "│ …       ┆ …          ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 160299  ┆ 6460236    ┆ 2023-06-0 ┆ [9770792, ┆ … ┆ true      ┆ [0, 0, …  ┆ [0.885766 ┆ [7, 30, … │\n",
       "│         ┆            ┆ 6         ┆ 9779541,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 35]       │\n",
       "│         ┆            ┆ 23:34:11  ┆ …         ┆   ┆           ┆           ┆ 0.035413, ┆           │\n",
       "│         ┆            ┆           ┆ 9786176]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.019348] ┆           │\n",
       "│ 160486  ┆ 6460241    ┆ 2023-06-0 ┆ [9785019, ┆ … ┆ true      ┆ [0, 0, …  ┆ [0.011101 ┆ [20, 5, … │\n",
       "│         ┆            ┆ 6         ┆ 9783057,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 31]       │\n",
       "│         ┆            ┆ 23:04:57  ┆ …         ┆   ┆           ┆           ┆ 0.809407, ┆           │\n",
       "│         ┆            ┆           ┆ 9790713]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.000218] ┆           │\n",
       "│ 160969  ┆ 6460253    ┆ 2023-06-0 ┆ [9789676, ┆ … ┆ true      ┆ [0, 0, …  ┆ [0.306943 ┆ [3, 7, …  │\n",
       "│         ┆            ┆ 6         ┆ 9788576,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 2]        │\n",
       "│         ┆            ┆ 23:26:47  ┆ …         ┆   ┆           ┆           ┆ 0.050109, ┆           │\n",
       "│         ┆            ┆           ┆ 9789674]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.805253] ┆           │\n",
       "│ 161198  ┆ 6460259    ┆ 2023-06-0 ┆ [9780295, ┆ … ┆ true      ┆ [0, 0, …  ┆ [0.256694 ┆ [2, 5, …  │\n",
       "│         ┆            ┆ 6         ┆ 9767342,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 1]        │\n",
       "│         ┆            ┆ 23:02:35  ┆ …         ┆   ┆           ┆           ┆ 0.002598, ┆           │\n",
       "│         ┆            ┆           ┆ 9790942]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.982929] ┆           │\n",
       "│ 161774  ┆ 6460276    ┆ 2023-06-0 ┆ [9776560, ┆ … ┆ true      ┆ [0, 0, …  ┆ [0.997622 ┆ [1, 31, … │\n",
       "│         ┆            ┆ 6         ┆ 9776544,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 34]       │\n",
       "│         ┆            ┆ 23:42:42  ┆ …         ┆   ┆           ┆           ┆ 0.001058, ┆           │\n",
       "│         ┆            ┆           ┆ 9789911]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.000239] ┆           │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_test\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_000, 2)\n",
      "┌───────────────┬─────────────┐\n",
      "│ ranked_scores ┆ labels      │\n",
      "│ ---           ┆ ---         │\n",
      "│ list[i64]     ┆ list[i64]   │\n",
      "╞═══════════════╪═════════════╡\n",
      "│ [3, 2, … 9]   ┆ [0, 0, … 0] │\n",
      "│ [4, 7, … 3]   ┆ [0, 0, … 0] │\n",
      "│ [2, 5, … 3]   ┆ [0, 0, … 0] │\n",
      "│ [9, 11, … 3]  ┆ [0, 0, … 0] │\n",
      "│ [2, 6, … 1]   ┆ [0, 0, … 1] │\n",
      "│ …             ┆ …           │\n",
      "│ [7, 30, … 35] ┆ [0, 0, … 0] │\n",
      "│ [20, 5, … 31] ┆ [0, 0, … 0] │\n",
      "│ [3, 7, … 2]   ┆ [0, 0, … 0] │\n",
      "│ [2, 5, … 1]   ┆ [0, 0, … 1] │\n",
      "│ [1, 31, … 34] ┆ [1, 0, … 0] │\n",
      "└───────────────┴─────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antot\\AppData\\Local\\Temp\\ipykernel_21888\\247236528.py:7: DeprecationWarning: `apply` is deprecated. It has been renamed to `map_elements`.\n",
      "  .apply(lambda row: [1 if rank == 1 else 0 for rank in row[\"ranked_scores\"]]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "# Update the 'labels' column to match the length of 'ranked_scores' and assign 1 to the highest rank\n",
    "df_test = df_test.with_columns(\n",
    "    pl.struct([\"ranked_scores\", \"scores\"])\n",
    "    .apply(lambda row: [1 if rank == 1 else 0 for rank in row[\"ranked_scores\"]]\n",
    "           if len(row[\"ranked_scores\"]) == len(row[\"scores\"]) else None)\n",
    "    .alias(\"labels\")\n",
    ")\n",
    "\n",
    "# Check for rows where labels are None (mismatched lengths)\n",
    "invalid_rows = df_test.filter(pl.col(\"labels\").is_null())\n",
    "\n",
    "if invalid_rows.height > 0:\n",
    "    print(\"Found rows with mismatched 'ranked_scores' and 'scores':\")\n",
    "    print(invalid_rows)\n",
    "\n",
    "# Verify the updated 'labels' column\n",
    "print(df_test.select([\"ranked_scores\", \"labels\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>impression_id</th><th>impression_time</th><th>article_id_fixed</th><th>article_ids_clicked</th><th>article_ids_inview</th><th>is_beyond_accuracy</th><th>labels</th><th>scores</th><th>ranked_scores</th></tr><tr><td>u32</td><td>u32</td><td>datetime[μs]</td><td>list[i32]</td><td>i32</td><td>list[i32]</td><td>bool</td><td>list[i64]</td><td>list[f64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>35982</td><td>6451339</td><td>2023-06-05 15:02:49</td><td>[9786268, 9782806, … 9789494]</td><td>9796527</td><td>[9796527, 7851321, … 9492777]</td><td>false</td><td>[0, 0, … 0]</td><td>[0.630941, 0.950646, … 0.008185]</td><td>[3, 2, … 9]</td></tr><tr><td>36012</td><td>6451363</td><td>2023-06-05 15:03:56</td><td>[9788323, 9788362, … 9790885]</td><td>9798532</td><td>[9798532, 9791602, … 9798958]</td><td>false</td><td>[0, 0, … 0]</td><td>[0.104358, 0.001216, … 0.179523]</td><td>[4, 7, … 3]</td></tr><tr><td>36162</td><td>6451382</td><td>2023-06-05 15:25:53</td><td>[9788524, 9788106, … 9790700]</td><td>9798498</td><td>[9798498, 9793856, … 9798724]</td><td>false</td><td>[0, 0, … 0]</td><td>[0.097785, 0.000392, … 0.015833]</td><td>[2, 5, … 3]</td></tr><tr><td>36162</td><td>6451383</td><td>2023-06-05 15:26:35</td><td>[9788524, 9788106, … 9790700]</td><td>9797419</td><td>[9797419, 9798829, … 9798805]</td><td>false</td><td>[0, 0, … 0]</td><td>[0.024571, 0.001634, … 0.580246]</td><td>[9, 11, … 3]</td></tr><tr><td>36162</td><td>6451385</td><td>2023-06-05 15:26:14</td><td>[9788524, 9788106, … 9790700]</td><td>9785014</td><td>[9785014, 9798958, … 9486080]</td><td>false</td><td>[0, 0, … 1]</td><td>[0.918962, 0.120063, … 0.9671]</td><td>[2, 6, … 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ user_id ┆ impression ┆ impressio ┆ article_i ┆ … ┆ is_beyond ┆ labels    ┆ scores    ┆ ranked_sc │\n",
       "│ ---     ┆ _id        ┆ n_time    ┆ d_fixed   ┆   ┆ _accuracy ┆ ---       ┆ ---       ┆ ores      │\n",
       "│ u32     ┆ ---        ┆ ---       ┆ ---       ┆   ┆ ---       ┆ list[i64] ┆ list[f64] ┆ ---       │\n",
       "│         ┆ u32        ┆ datetime[ ┆ list[i32] ┆   ┆ bool      ┆           ┆           ┆ list[i64] │\n",
       "│         ┆            ┆ μs]       ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 35982   ┆ 6451339    ┆ 2023-06-0 ┆ [9786268, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.630941 ┆ [3, 2, …  │\n",
       "│         ┆            ┆ 5         ┆ 9782806,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 9]        │\n",
       "│         ┆            ┆ 15:02:49  ┆ …         ┆   ┆           ┆           ┆ 0.950646, ┆           │\n",
       "│         ┆            ┆           ┆ 9789494]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.008185] ┆           │\n",
       "│ 36012   ┆ 6451363    ┆ 2023-06-0 ┆ [9788323, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.104358 ┆ [4, 7, …  │\n",
       "│         ┆            ┆ 5         ┆ 9788362,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 3]        │\n",
       "│         ┆            ┆ 15:03:56  ┆ …         ┆   ┆           ┆           ┆ 0.001216, ┆           │\n",
       "│         ┆            ┆           ┆ 9790885]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.179523] ┆           │\n",
       "│ 36162   ┆ 6451382    ┆ 2023-06-0 ┆ [9788524, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.097785 ┆ [2, 5, …  │\n",
       "│         ┆            ┆ 5         ┆ 9788106,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 3]        │\n",
       "│         ┆            ┆ 15:25:53  ┆ …         ┆   ┆           ┆           ┆ 0.000392, ┆           │\n",
       "│         ┆            ┆           ┆ 9790700]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.015833] ┆           │\n",
       "│ 36162   ┆ 6451383    ┆ 2023-06-0 ┆ [9788524, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.024571 ┆ [9, 11, … │\n",
       "│         ┆            ┆ 5         ┆ 9788106,  ┆   ┆           ┆ 0]        ┆ ,         ┆ 3]        │\n",
       "│         ┆            ┆ 15:26:35  ┆ …         ┆   ┆           ┆           ┆ 0.001634, ┆           │\n",
       "│         ┆            ┆           ┆ 9790700]  ┆   ┆           ┆           ┆ …         ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆ 0.580246] ┆           │\n",
       "│ 36162   ┆ 6451385    ┆ 2023-06-0 ┆ [9788524, ┆ … ┆ false     ┆ [0, 0, …  ┆ [0.918962 ┆ [2, 6, …  │\n",
       "│         ┆            ┆ 5         ┆ 9788106,  ┆   ┆           ┆ 1]        ┆ ,         ┆ 1]        │\n",
       "│         ┆            ┆ 15:26:14  ┆ …         ┆   ┆           ┆           ┆ 0.120063, ┆           │\n",
       "│         ┆            ┆           ┆ 9790700]  ┆   ┆           ┆           ┆ … 0.9671] ┆           │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 rows of df_test have been saved as 'df_test_head.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required library\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_test is already defined; otherwise, create or assign it here\n",
    "# For example, df_test = pd.DataFrame(data) \n",
    "\n",
    "# Check if df_test is a DataFrame\n",
    "if not isinstance(df_test, pd.DataFrame):\n",
    "    # Convert to DataFrame if it isn't one\n",
    "    df_test = pd.DataFrame(df_test)\n",
    "\n",
    "# Save the first 5 rows of the DataFrame to a CSV file\n",
    "df_test.head().to_csv(\"df_test_head.csv\", index=False)\n",
    "\n",
    "print(\"The first 5 rows of df_test have been saved as 'df_test_head.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUC: 100%|█████████████████████████████████| 1000/1000 [00:02<00:00, 396.30it/s]\n",
      "AUC: 100%|███████████████████████████████| 1000/1000 [00:00<00:00, 17663.20it/s]\n",
      "AUC: 100%|████████████████████████████████| 1000/1000 [00:00<00:00, 7731.24it/s]\n",
      "AUC: 100%|████████████████████████████████| 1000/1000 [00:00<00:00, 6861.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 1.0,\n",
       "    \"mrr\": 1.0,\n",
       "    \"ndcg@5\": 1.0,\n",
       "    \"ndcg@10\": 1.0\n",
       "}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics = MetricEvaluator(\n",
    "    labels=df_test[\"labels\"].to_list(),\n",
    "    predictions=df_test[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the predictions to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kanei concatination beyond and non beyond accuracy kai meta kanei to ta predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUC: 100%|█████████████████████████████████| 1000/1000 [00:02<00:00, 367.36it/s]\n",
      "AUC: 100%|███████████████████████████████| 1000/1000 [00:00<00:00, 17145.15it/s]\n",
      "AUC: 100%|████████████████████████████████| 1000/1000 [00:00<00:00, 5578.18it/s]\n",
      "AUC: 100%|████████████████████████████████| 1000/1000 [00:00<00:00, 8029.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 1.0,\n",
       "    \"mrr\": 1.0,\n",
       "    \"ndcg@5\": 1.0,\n",
       "    \"ndcg@10\": 1.0\n",
       "}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = MetricEvaluator(\n",
    "    labels=df_test[\"labels\"].to_list(),\n",
    "    predictions=df_test[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is using the validation, simply add the testset to your flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2446it [00:00, 27609.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping ebnerd_predictions/predictions.txt to ebnerd_predictions/ebnerd_small_predictions-NRMSModel.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "write_submission_file(\n",
    "    impression_ids=df_test[DEFAULT_IMPRESSION_ID_COL],\n",
    "    prediction_scores=df_test[\"ranked_scores\"],\n",
    "    path=DUMP_DIR.joinpath(\"predictions.txt\"),\n",
    "    filename_zip=f\"{DATASPLIT}_predictions-{MODEL_NAME}.zip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
