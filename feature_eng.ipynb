{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Instantiate the LabelEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the datasets based on the current working directory\n",
    "base_dir = os.path.join(os.getcwd(), 'ebnerd_large')\n",
    "behavior_file = os.path.join(base_dir, 'train', 'behaviors.parquet')\n",
    "history_file = os.path.join(base_dir, 'train', 'history.parquet')\n",
    "articles_file = os.path.join(base_dir, 'articles.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>impression_time</th>\n",
       "      <th>read_time</th>\n",
       "      <th>scroll_percentage</th>\n",
       "      <th>device_type</th>\n",
       "      <th>article_ids_inview</th>\n",
       "      <th>article_ids_clicked</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_sso_user</th>\n",
       "      <th>gender</th>\n",
       "      <th>postcode</th>\n",
       "      <th>age</th>\n",
       "      <th>is_subscriber</th>\n",
       "      <th>session_id</th>\n",
       "      <th>next_read_time</th>\n",
       "      <th>next_scroll_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-21 21:35:07</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9482380, 9775183, 9744403, 9775297, 9774020, ...</td>\n",
       "      <td>[9775183]</td>\n",
       "      <td>18293</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>265</td>\n",
       "      <td>34.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-21 21:32:33</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9774557, 9774516, 9775331, 9775277, 9759966]</td>\n",
       "      <td>[9759966]</td>\n",
       "      <td>18293</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>265</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-21 21:33:32</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9759966, 9774557, 9775352, 9746360, 9772601, ...</td>\n",
       "      <td>[9774652]</td>\n",
       "      <td>18293</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>265</td>\n",
       "      <td>78.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-21 21:38:17</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9774580, 9775131, 9775202, 9774789, 9774972, ...</td>\n",
       "      <td>[9775184]</td>\n",
       "      <td>18293</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>265</td>\n",
       "      <td>6.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-21 21:36:02</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9774826, 9775171, 9775076, 9769624, 9775056, ...</td>\n",
       "      <td>[9774648]</td>\n",
       "      <td>18293</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>265</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impression_id  article_id     impression_time  read_time  \\\n",
       "0          47727         NaN 2023-05-21 21:35:07       20.0   \n",
       "1          47731         NaN 2023-05-21 21:32:33       13.0   \n",
       "2          47736         NaN 2023-05-21 21:33:32       17.0   \n",
       "3          47737         NaN 2023-05-21 21:38:17       27.0   \n",
       "4          47740         NaN 2023-05-21 21:36:02       48.0   \n",
       "\n",
       "   scroll_percentage  device_type  \\\n",
       "0                NaN            1   \n",
       "1                NaN            1   \n",
       "2                NaN            1   \n",
       "3                NaN            1   \n",
       "4                NaN            1   \n",
       "\n",
       "                                  article_ids_inview article_ids_clicked  \\\n",
       "0  [9482380, 9775183, 9744403, 9775297, 9774020, ...           [9775183]   \n",
       "1      [9774557, 9774516, 9775331, 9775277, 9759966]           [9759966]   \n",
       "2  [9759966, 9774557, 9775352, 9746360, 9772601, ...           [9774652]   \n",
       "3  [9774580, 9775131, 9775202, 9774789, 9774972, ...           [9775184]   \n",
       "4  [9774826, 9775171, 9775076, 9769624, 9775056, ...           [9774648]   \n",
       "\n",
       "   user_id  is_sso_user  gender  postcode  age  is_subscriber  session_id  \\\n",
       "0    18293        False     NaN       NaN  NaN          False         265   \n",
       "1    18293        False     NaN       NaN  NaN          False         265   \n",
       "2    18293        False     NaN       NaN  NaN          False         265   \n",
       "3    18293        False     NaN       NaN  NaN          False         265   \n",
       "4    18293        False     NaN       NaN  NaN          False         265   \n",
       "\n",
       "   next_read_time  next_scroll_percentage  \n",
       "0            34.0                   100.0  \n",
       "1            45.0                   100.0  \n",
       "2            78.0                   100.0  \n",
       "3             6.0                    52.0  \n",
       "4            32.0                   100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "History Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>impression_time_fixed</th>\n",
       "      <th>scroll_percentage_fixed</th>\n",
       "      <th>article_id_fixed</th>\n",
       "      <th>read_time_fixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10029</td>\n",
       "      <td>[2023-04-28T06:16:57.000000, 2023-04-28T06:17:...</td>\n",
       "      <td>[23.0, 69.0, 27.0, nan, 47.0, 38.0, 100.0, 12....</td>\n",
       "      <td>[9735579, 9739888, 9739471, 9739864, 9738441, ...</td>\n",
       "      <td>[28.0, 24.0, 11.0, 107.0, 8.0, 7.0, 20.0, 5.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10033</td>\n",
       "      <td>[2023-04-27T11:11:32.000000, 2023-04-27T11:12:...</td>\n",
       "      <td>[33.0, 41.0, 33.0, 100.0, 68.0, 38.0, 1.0, 58....</td>\n",
       "      <td>[9738139, 9738263, 9738139, 9738760, 9738777, ...</td>\n",
       "      <td>[2.0, 2.0, 718.0, 18.0, 26.0, 78.0, 3.0, 11.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10034</td>\n",
       "      <td>[2023-04-30T09:46:57.000000, 2023-04-30T09:47:...</td>\n",
       "      <td>[nan, 88.0, 27.0, nan, 23.0, 100.0, 100.0, 22....</td>\n",
       "      <td>[9742693, 9742686, 9744016, 9743818, 9744922, ...</td>\n",
       "      <td>[21.0, 103.0, 28.0, 0.0, 5.0, 34.0, 14.0, 14.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10041</td>\n",
       "      <td>[2023-04-27T15:15:28.000000, 2023-04-27T15:16:...</td>\n",
       "      <td>[78.0, 41.0, 4.0, 16.0, 22.0, 32.0, 11.0, 94.0...</td>\n",
       "      <td>[9739035, 9738303, 9737243, 9739634, 9739802, ...</td>\n",
       "      <td>[12.0, 11.0, 3.0, 3.0, 4.0, 13.0, 29.0, 24.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10103</td>\n",
       "      <td>[2023-04-27T15:37:35.000000, 2023-04-27T15:38:...</td>\n",
       "      <td>[100.0, nan, 100.0, 100.0, 100.0, 28.0, 82.0, ...</td>\n",
       "      <td>[9739035, 9739164, 9741803, 9740087, 9741986, ...</td>\n",
       "      <td>[45.0, 8.0, 61.0, 72.0, 56.0, 3.0, 22.0, 16.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                              impression_time_fixed  \\\n",
       "0    10029  [2023-04-28T06:16:57.000000, 2023-04-28T06:17:...   \n",
       "1    10033  [2023-04-27T11:11:32.000000, 2023-04-27T11:12:...   \n",
       "2    10034  [2023-04-30T09:46:57.000000, 2023-04-30T09:47:...   \n",
       "3    10041  [2023-04-27T15:15:28.000000, 2023-04-27T15:16:...   \n",
       "4    10103  [2023-04-27T15:37:35.000000, 2023-04-27T15:38:...   \n",
       "\n",
       "                             scroll_percentage_fixed  \\\n",
       "0  [23.0, 69.0, 27.0, nan, 47.0, 38.0, 100.0, 12....   \n",
       "1  [33.0, 41.0, 33.0, 100.0, 68.0, 38.0, 1.0, 58....   \n",
       "2  [nan, 88.0, 27.0, nan, 23.0, 100.0, 100.0, 22....   \n",
       "3  [78.0, 41.0, 4.0, 16.0, 22.0, 32.0, 11.0, 94.0...   \n",
       "4  [100.0, nan, 100.0, 100.0, 100.0, 28.0, 82.0, ...   \n",
       "\n",
       "                                    article_id_fixed  \\\n",
       "0  [9735579, 9739888, 9739471, 9739864, 9738441, ...   \n",
       "1  [9738139, 9738263, 9738139, 9738760, 9738777, ...   \n",
       "2  [9742693, 9742686, 9744016, 9743818, 9744922, ...   \n",
       "3  [9739035, 9738303, 9737243, 9739634, 9739802, ...   \n",
       "4  [9739035, 9739164, 9741803, 9740087, 9741986, ...   \n",
       "\n",
       "                                     read_time_fixed  \n",
       "0  [28.0, 24.0, 11.0, 107.0, 8.0, 7.0, 20.0, 5.0,...  \n",
       "1  [2.0, 2.0, 718.0, 18.0, 26.0, 78.0, 3.0, 11.0,...  \n",
       "2  [21.0, 103.0, 28.0, 0.0, 5.0, 34.0, 14.0, 14.0...  \n",
       "3  [12.0, 11.0, 3.0, 3.0, 4.0, 13.0, 29.0, 24.0, ...  \n",
       "4  [45.0, 8.0, 61.0, 72.0, 56.0, 3.0, 22.0, 16.0,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Articles Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>last_modified_time</th>\n",
       "      <th>premium</th>\n",
       "      <th>body</th>\n",
       "      <th>published_time</th>\n",
       "      <th>image_ids</th>\n",
       "      <th>article_type</th>\n",
       "      <th>url</th>\n",
       "      <th>...</th>\n",
       "      <th>entity_groups</th>\n",
       "      <th>topics</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category_str</th>\n",
       "      <th>total_inviews</th>\n",
       "      <th>total_pageviews</th>\n",
       "      <th>total_read_time</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000022</td>\n",
       "      <td>Hanks beskyldt for mishandling</td>\n",
       "      <td>Tom Hanks har angiveligt mishandlet sin afdøde...</td>\n",
       "      <td>2023-06-29 06:20:32</td>\n",
       "      <td>False</td>\n",
       "      <td>Tom Hanks skulle angiveligt have mishandlet si...</td>\n",
       "      <td>2006-09-20 09:24:18</td>\n",
       "      <td>[3518381]</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/underholdning/udlandke...</td>\n",
       "      <td>...</td>\n",
       "      <td>[PER]</td>\n",
       "      <td>[Kriminalitet, Kendt, Underholdning, Personfar...</td>\n",
       "      <td>414</td>\n",
       "      <td>[432]</td>\n",
       "      <td>underholdning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000063</td>\n",
       "      <td>Bostrups aske spredt i Furesøen</td>\n",
       "      <td>Studieværten blev mindet med glad festlighed</td>\n",
       "      <td>2023-06-29 06:20:32</td>\n",
       "      <td>False</td>\n",
       "      <td>Strålende sensommersol. Jazzede toner. Glas me...</td>\n",
       "      <td>2006-09-24 07:45:30</td>\n",
       "      <td>[3170935, 3170939]</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/nyheder/samfund/articl...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kendt, Underholdning, Begivenhed, Personlig b...</td>\n",
       "      <td>118</td>\n",
       "      <td>[133]</td>\n",
       "      <td>nyheder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5155</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000613</td>\n",
       "      <td>Jesper Olsen ramt af hjerneblødning</td>\n",
       "      <td>Den tidligere danske landsholdsspiller i fodbo...</td>\n",
       "      <td>2023-06-29 06:20:33</td>\n",
       "      <td>False</td>\n",
       "      <td>Jesper Olsen, der er noteret for 43 kampe på d...</td>\n",
       "      <td>2006-05-09 11:29:00</td>\n",
       "      <td>[3164998]</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/sport/fodbold/landshol...</td>\n",
       "      <td>...</td>\n",
       "      <td>[LOC, PER, PER, PER]</td>\n",
       "      <td>[Kendt, Sport, Fodbold, Sundhed, Sygdom og beh...</td>\n",
       "      <td>142</td>\n",
       "      <td>[196, 271]</td>\n",
       "      <td>sport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000700</td>\n",
       "      <td>Madonna topløs med heste</td>\n",
       "      <td>47-årige Madonna poserer både topløs og sammen...</td>\n",
       "      <td>2023-06-29 06:20:33</td>\n",
       "      <td>False</td>\n",
       "      <td>Skal du have stillet Madonna-sulten inden konc...</td>\n",
       "      <td>2006-05-04 11:03:12</td>\n",
       "      <td>[3172046]</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/underholdning/udlandke...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kendt, Livsstil, Underholdning]</td>\n",
       "      <td>414</td>\n",
       "      <td>[432]</td>\n",
       "      <td>underholdning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000840</td>\n",
       "      <td>Otto Brandenburg er død</td>\n",
       "      <td>Sangeren og skuespilleren Otto Brandenburg er ...</td>\n",
       "      <td>2023-06-29 06:20:33</td>\n",
       "      <td>False</td>\n",
       "      <td>'Og lidt for Susanne, Birgitte og Hanne... ' '...</td>\n",
       "      <td>2007-03-01 18:34:00</td>\n",
       "      <td>[3914446]</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/nyheder/samfund/articl...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kendt, Underholdning, Begivenhed, Personlig b...</td>\n",
       "      <td>118</td>\n",
       "      <td>[133]</td>\n",
       "      <td>nyheder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                title  \\\n",
       "0     3000022       Hanks beskyldt for mishandling   \n",
       "1     3000063      Bostrups aske spredt i Furesøen   \n",
       "2     3000613  Jesper Olsen ramt af hjerneblødning   \n",
       "3     3000700             Madonna topløs med heste   \n",
       "4     3000840              Otto Brandenburg er død   \n",
       "\n",
       "                                            subtitle  last_modified_time  \\\n",
       "0  Tom Hanks har angiveligt mishandlet sin afdøde... 2023-06-29 06:20:32   \n",
       "1       Studieværten blev mindet med glad festlighed 2023-06-29 06:20:32   \n",
       "2  Den tidligere danske landsholdsspiller i fodbo... 2023-06-29 06:20:33   \n",
       "3  47-årige Madonna poserer både topløs og sammen... 2023-06-29 06:20:33   \n",
       "4  Sangeren og skuespilleren Otto Brandenburg er ... 2023-06-29 06:20:33   \n",
       "\n",
       "   premium                                               body  \\\n",
       "0    False  Tom Hanks skulle angiveligt have mishandlet si...   \n",
       "1    False  Strålende sensommersol. Jazzede toner. Glas me...   \n",
       "2    False  Jesper Olsen, der er noteret for 43 kampe på d...   \n",
       "3    False  Skal du have stillet Madonna-sulten inden konc...   \n",
       "4    False  'Og lidt for Susanne, Birgitte og Hanne... ' '...   \n",
       "\n",
       "       published_time           image_ids     article_type  \\\n",
       "0 2006-09-20 09:24:18           [3518381]  article_default   \n",
       "1 2006-09-24 07:45:30  [3170935, 3170939]  article_default   \n",
       "2 2006-05-09 11:29:00           [3164998]  article_default   \n",
       "3 2006-05-04 11:03:12           [3172046]  article_default   \n",
       "4 2007-03-01 18:34:00           [3914446]  article_default   \n",
       "\n",
       "                                                 url  ...  \\\n",
       "0  https://ekstrabladet.dk/underholdning/udlandke...  ...   \n",
       "1  https://ekstrabladet.dk/nyheder/samfund/articl...  ...   \n",
       "2  https://ekstrabladet.dk/sport/fodbold/landshol...  ...   \n",
       "3  https://ekstrabladet.dk/underholdning/udlandke...  ...   \n",
       "4  https://ekstrabladet.dk/nyheder/samfund/articl...  ...   \n",
       "\n",
       "          entity_groups                                             topics  \\\n",
       "0                 [PER]  [Kriminalitet, Kendt, Underholdning, Personfar...   \n",
       "1                    []  [Kendt, Underholdning, Begivenhed, Personlig b...   \n",
       "2  [LOC, PER, PER, PER]  [Kendt, Sport, Fodbold, Sundhed, Sygdom og beh...   \n",
       "3                    []                   [Kendt, Livsstil, Underholdning]   \n",
       "4                    []  [Kendt, Underholdning, Begivenhed, Personlig b...   \n",
       "\n",
       "  category  subcategory   category_str total_inviews  total_pageviews  \\\n",
       "0      414        [432]  underholdning           NaN              NaN   \n",
       "1      118        [133]        nyheder           NaN              NaN   \n",
       "2      142   [196, 271]          sport           NaN              NaN   \n",
       "3      414        [432]  underholdning           NaN              NaN   \n",
       "4      118        [133]        nyheder           NaN              NaN   \n",
       "\n",
       "   total_read_time  sentiment_score  sentiment_label  \n",
       "0              NaN           0.9911         Negative  \n",
       "1              NaN           0.5155          Neutral  \n",
       "2              NaN           0.9876         Negative  \n",
       "3              NaN           0.8786          Neutral  \n",
       "4              NaN           0.9468         Negative  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Load Datasets\n",
    "# Load each dataset from the specified paths\n",
    "behavior_df = pd.read_parquet(behavior_file)\n",
    "history_df = pd.read_parquet(history_file)\n",
    "articles_df = pd.read_parquet(articles_file)\n",
    "\n",
    "# Display the first few rows of each dataset to confirm loading worked\n",
    "print(\"Behavior Data:\")\n",
    "display(behavior_df.head())\n",
    "\n",
    "print(\"\\nHistory Data:\")\n",
    "display(history_df.head())\n",
    "\n",
    "print(\"\\nArticles Data:\")\n",
    "display(articles_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impression_id                    0\n",
      "article_id                 8458027\n",
      "impression_time                  0\n",
      "read_time                        0\n",
      "scroll_percentage          8523902\n",
      "device_type                      0\n",
      "article_ids_inview               0\n",
      "article_ids_clicked              0\n",
      "user_id                          0\n",
      "is_sso_user                      0\n",
      "gender                    11176907\n",
      "postcode                  11795148\n",
      "age                       11694243\n",
      "is_subscriber                    0\n",
      "session_id                       0\n",
      "next_read_time              319928\n",
      "next_scroll_percentage     1360982\n",
      "dtype: int64\n",
      "user_id                    0\n",
      "impression_time_fixed      0\n",
      "scroll_percentage_fixed    0\n",
      "article_id_fixed           0\n",
      "read_time_fixed            0\n",
      "dtype: int64\n",
      "article_id                 0\n",
      "title                      0\n",
      "subtitle                   0\n",
      "last_modified_time         0\n",
      "premium                    0\n",
      "body                       0\n",
      "published_time             0\n",
      "image_ids              14322\n",
      "article_type               0\n",
      "url                        0\n",
      "ner_clusters               0\n",
      "entity_groups              0\n",
      "topics                     0\n",
      "category                   0\n",
      "subcategory                0\n",
      "category_str               0\n",
      "total_inviews         107205\n",
      "total_pageviews       108600\n",
      "total_read_time       108600\n",
      "sentiment_score            0\n",
      "sentiment_label            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(behavior_df.isnull().sum())\n",
    "print(history_df.isnull().sum())\n",
    "print(articles_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['impression_id', 'article_id', 'impression_time', 'read_time',\n",
      "       'scroll_percentage', 'device_type', 'article_ids_inview',\n",
      "       'article_ids_clicked', 'user_id', 'is_sso_user', 'gender', 'postcode',\n",
      "       'age', 'is_subscriber', 'session_id', 'next_read_time',\n",
      "       'next_scroll_percentage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(behavior_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed that we have a lot of missing values for the gender , age and postcode attributes and since they are not relevant for our NRMS we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now drop columns with high missing values\n",
    "behavior_df = behavior_df.drop(columns=['impression_id', 'article_id','gender', 'postcode', 'age','scroll_percentage','device_type'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impression_time                 0\n",
      "read_time                       0\n",
      "article_ids_inview              0\n",
      "article_ids_clicked             0\n",
      "user_id                         0\n",
      "is_sso_user                     0\n",
      "is_subscriber                   0\n",
      "session_id                      0\n",
      "next_read_time             319928\n",
      "next_scroll_percentage    1360982\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(behavior_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now drop columns with high missing values\n",
    "articles_df = articles_df.drop(columns=['image_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['article_id', 'title', 'subtitle', 'last_modified_time', 'premium',\n",
      "       'body', 'published_time', 'article_type', 'url', 'ner_clusters',\n",
      "       'entity_groups', 'topics', 'category', 'subcategory', 'category_str',\n",
      "       'total_inviews', 'total_pageviews', 'total_read_time',\n",
      "       'sentiment_score', 'sentiment_label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(articles_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_id                 0\n",
      "title                      0\n",
      "subtitle                   0\n",
      "last_modified_time         0\n",
      "premium                    0\n",
      "body                       0\n",
      "published_time             0\n",
      "article_type               0\n",
      "url                        0\n",
      "ner_clusters               0\n",
      "entity_groups              0\n",
      "topics                     0\n",
      "category                   0\n",
      "subcategory                0\n",
      "category_str               0\n",
      "total_inviews         107205\n",
      "total_pageviews       108600\n",
      "total_read_time       108600\n",
      "sentiment_score            0\n",
      "sentiment_label            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(articles_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['article_id', 'title', 'subtitle', 'last_modified_time', 'premium',\n",
      "       'body', 'published_time', 'article_type', 'url', 'ner_clusters',\n",
      "       'entity_groups', 'topics', 'category', 'subcategory', 'category_str',\n",
      "       'total_inviews', 'total_pageviews', 'total_read_time',\n",
      "       'sentiment_score', 'sentiment_label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(articles_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the article dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loads only the specified columns, converts subcategory_ids to a single string format, and applies LabelEncoder for model compatibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>last_modified_time</th>\n",
       "      <th>premium</th>\n",
       "      <th>body</th>\n",
       "      <th>published_time</th>\n",
       "      <th>article_type</th>\n",
       "      <th>ner_clusters</th>\n",
       "      <th>entity_groups</th>\n",
       "      <th>topics</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory_encoded</th>\n",
       "      <th>category_str</th>\n",
       "      <th>total_inviews</th>\n",
       "      <th>total_pageviews</th>\n",
       "      <th>total_read_time</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000022</td>\n",
       "      <td>Hanks beskyldt for mishandling</td>\n",
       "      <td>Tom Hanks har angiveligt mishandlet sin afdøde...</td>\n",
       "      <td>2023-06-29 06:20:32</td>\n",
       "      <td>False</td>\n",
       "      <td>Tom Hanks skulle angiveligt have mishandlet si...</td>\n",
       "      <td>2006-09-20 09:24:18</td>\n",
       "      <td>article_default</td>\n",
       "      <td>[David Gardner]</td>\n",
       "      <td>[PER]</td>\n",
       "      <td>[Kriminalitet, Kendt, Underholdning, Personfar...</td>\n",
       "      <td>414</td>\n",
       "      <td>219</td>\n",
       "      <td>underholdning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000063</td>\n",
       "      <td>Bostrups aske spredt i Furesøen</td>\n",
       "      <td>Studieværten blev mindet med glad festlighed</td>\n",
       "      <td>2023-06-29 06:20:32</td>\n",
       "      <td>False</td>\n",
       "      <td>Strålende sensommersol. Jazzede toner. Glas me...</td>\n",
       "      <td>2006-09-24 07:45:30</td>\n",
       "      <td>article_default</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kendt, Underholdning, Begivenhed, Personlig b...</td>\n",
       "      <td>118</td>\n",
       "      <td>10</td>\n",
       "      <td>nyheder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5155</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000613</td>\n",
       "      <td>Jesper Olsen ramt af hjerneblødning</td>\n",
       "      <td>Den tidligere danske landsholdsspiller i fodbo...</td>\n",
       "      <td>2023-06-29 06:20:33</td>\n",
       "      <td>False</td>\n",
       "      <td>Jesper Olsen, der er noteret for 43 kampe på d...</td>\n",
       "      <td>2006-05-09 11:29:00</td>\n",
       "      <td>article_default</td>\n",
       "      <td>[Frankrig, Jesper Olsen, Jesper Olsen, Jesper ...</td>\n",
       "      <td>[LOC, PER, PER, PER]</td>\n",
       "      <td>[Kendt, Sport, Fodbold, Sundhed, Sygdom og beh...</td>\n",
       "      <td>142</td>\n",
       "      <td>101</td>\n",
       "      <td>sport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000700</td>\n",
       "      <td>Madonna topløs med heste</td>\n",
       "      <td>47-årige Madonna poserer både topløs og sammen...</td>\n",
       "      <td>2023-06-29 06:20:33</td>\n",
       "      <td>False</td>\n",
       "      <td>Skal du have stillet Madonna-sulten inden konc...</td>\n",
       "      <td>2006-05-04 11:03:12</td>\n",
       "      <td>article_default</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kendt, Livsstil, Underholdning]</td>\n",
       "      <td>414</td>\n",
       "      <td>219</td>\n",
       "      <td>underholdning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000840</td>\n",
       "      <td>Otto Brandenburg er død</td>\n",
       "      <td>Sangeren og skuespilleren Otto Brandenburg er ...</td>\n",
       "      <td>2023-06-29 06:20:33</td>\n",
       "      <td>False</td>\n",
       "      <td>'Og lidt for Susanne, Birgitte og Hanne... ' '...</td>\n",
       "      <td>2007-03-01 18:34:00</td>\n",
       "      <td>article_default</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kendt, Underholdning, Begivenhed, Personlig b...</td>\n",
       "      <td>118</td>\n",
       "      <td>10</td>\n",
       "      <td>nyheder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                title  \\\n",
       "0     3000022       Hanks beskyldt for mishandling   \n",
       "1     3000063      Bostrups aske spredt i Furesøen   \n",
       "2     3000613  Jesper Olsen ramt af hjerneblødning   \n",
       "3     3000700             Madonna topløs med heste   \n",
       "4     3000840              Otto Brandenburg er død   \n",
       "\n",
       "                                            subtitle  last_modified_time  \\\n",
       "0  Tom Hanks har angiveligt mishandlet sin afdøde... 2023-06-29 06:20:32   \n",
       "1       Studieværten blev mindet med glad festlighed 2023-06-29 06:20:32   \n",
       "2  Den tidligere danske landsholdsspiller i fodbo... 2023-06-29 06:20:33   \n",
       "3  47-årige Madonna poserer både topløs og sammen... 2023-06-29 06:20:33   \n",
       "4  Sangeren og skuespilleren Otto Brandenburg er ... 2023-06-29 06:20:33   \n",
       "\n",
       "   premium                                               body  \\\n",
       "0    False  Tom Hanks skulle angiveligt have mishandlet si...   \n",
       "1    False  Strålende sensommersol. Jazzede toner. Glas me...   \n",
       "2    False  Jesper Olsen, der er noteret for 43 kampe på d...   \n",
       "3    False  Skal du have stillet Madonna-sulten inden konc...   \n",
       "4    False  'Og lidt for Susanne, Birgitte og Hanne... ' '...   \n",
       "\n",
       "       published_time     article_type  \\\n",
       "0 2006-09-20 09:24:18  article_default   \n",
       "1 2006-09-24 07:45:30  article_default   \n",
       "2 2006-05-09 11:29:00  article_default   \n",
       "3 2006-05-04 11:03:12  article_default   \n",
       "4 2007-03-01 18:34:00  article_default   \n",
       "\n",
       "                                        ner_clusters         entity_groups  \\\n",
       "0                                    [David Gardner]                 [PER]   \n",
       "1                                                 []                    []   \n",
       "2  [Frankrig, Jesper Olsen, Jesper Olsen, Jesper ...  [LOC, PER, PER, PER]   \n",
       "3                                                 []                    []   \n",
       "4                                                 []                    []   \n",
       "\n",
       "                                              topics  category  \\\n",
       "0  [Kriminalitet, Kendt, Underholdning, Personfar...       414   \n",
       "1  [Kendt, Underholdning, Begivenhed, Personlig b...       118   \n",
       "2  [Kendt, Sport, Fodbold, Sundhed, Sygdom og beh...       142   \n",
       "3                   [Kendt, Livsstil, Underholdning]       414   \n",
       "4  [Kendt, Underholdning, Begivenhed, Personlig b...       118   \n",
       "\n",
       "   subcategory_encoded   category_str  total_inviews  total_pageviews  \\\n",
       "0                  219  underholdning            NaN              NaN   \n",
       "1                   10        nyheder            NaN              NaN   \n",
       "2                  101          sport            NaN              NaN   \n",
       "3                  219  underholdning            NaN              NaN   \n",
       "4                   10        nyheder            NaN              NaN   \n",
       "\n",
       "   total_read_time  sentiment_score sentiment_label  \n",
       "0              NaN           0.9911        Negative  \n",
       "1              NaN           0.5155         Neutral  \n",
       "2              NaN           0.9876        Negative  \n",
       "3              NaN           0.8786         Neutral  \n",
       "4              NaN           0.9468        Negative  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the correct column names, let's proceed with the correct script\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Specify the correct columns based on the user's provided column names\n",
    "articles_columns = ['article_id', 'title', 'subtitle', 'last_modified_time', 'premium',\n",
    "       'body', 'published_time', 'article_type', 'url', 'ner_clusters',\n",
    "       'entity_groups', 'topics', 'category', 'subcategory', 'category_str',\n",
    "       'total_inviews', 'total_pageviews', 'total_read_time',\n",
    "       'sentiment_score', 'sentiment_label']\n",
    "\n",
    "# Load only the necessary columns from the articles file\n",
    "articles_df = pd.read_parquet(articles_file, columns=articles_columns)\n",
    "\n",
    "# Convert subcategory from list to a single string (assuming it's a list of IDs)\n",
    "articles_df['subcategory'] = articles_df['subcategory'].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "# Apply LabelEncoder to transform 'subcategory' into a numeric format\n",
    "label_encoder = LabelEncoder()\n",
    "articles_df['subcategory_encoded'] = label_encoder.fit_transform(articles_df['subcategory'])\n",
    "\n",
    "# Display the resulting DataFrame to verify changes\n",
    "articles_df[['article_id', 'title', 'subtitle', 'last_modified_time', 'premium',\n",
    "       'body', 'published_time', 'article_type', 'ner_clusters',\n",
    "       'entity_groups', 'topics', 'category','subcategory_encoded', 'category_str',\n",
    "       'total_inviews', 'total_pageviews', 'total_read_time',\n",
    "       'sentiment_score', 'sentiment_label']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will:\n",
    "\n",
    "Convert last_modified_time and published_time to milliseconds.\n",
    "Calculate the time_interval in milliseconds between the mod_time and pub_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>last_modified_time</th>\n",
       "      <th>premium</th>\n",
       "      <th>body</th>\n",
       "      <th>published_time</th>\n",
       "      <th>article_type</th>\n",
       "      <th>url</th>\n",
       "      <th>ner_clusters</th>\n",
       "      <th>...</th>\n",
       "      <th>category_str</th>\n",
       "      <th>total_inviews</th>\n",
       "      <th>total_pageviews</th>\n",
       "      <th>total_read_time</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>subcategory_encoded</th>\n",
       "      <th>mod_time</th>\n",
       "      <th>pub_time</th>\n",
       "      <th>time_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000022</td>\n",
       "      <td>Hanks beskyldt for mishandling</td>\n",
       "      <td>Tom Hanks har angiveligt mishandlet sin afdøde...</td>\n",
       "      <td>2023-06-29 06:20:32</td>\n",
       "      <td>False</td>\n",
       "      <td>Tom Hanks skulle angiveligt have mishandlet si...</td>\n",
       "      <td>2006-09-20 09:24:18</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/underholdning/udlandke...</td>\n",
       "      <td>[David Gardner]</td>\n",
       "      <td>...</td>\n",
       "      <td>underholdning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>Negative</td>\n",
       "      <td>219</td>\n",
       "      <td>1688019632</td>\n",
       "      <td>1158744258</td>\n",
       "      <td>529275374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000063</td>\n",
       "      <td>Bostrups aske spredt i Furesøen</td>\n",
       "      <td>Studieværten blev mindet med glad festlighed</td>\n",
       "      <td>2023-06-29 06:20:32</td>\n",
       "      <td>False</td>\n",
       "      <td>Strålende sensommersol. Jazzede toner. Glas me...</td>\n",
       "      <td>2006-09-24 07:45:30</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/nyheder/samfund/articl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>nyheder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5155</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>10</td>\n",
       "      <td>1688019632</td>\n",
       "      <td>1159083930</td>\n",
       "      <td>528935702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000613</td>\n",
       "      <td>Jesper Olsen ramt af hjerneblødning</td>\n",
       "      <td>Den tidligere danske landsholdsspiller i fodbo...</td>\n",
       "      <td>2023-06-29 06:20:33</td>\n",
       "      <td>False</td>\n",
       "      <td>Jesper Olsen, der er noteret for 43 kampe på d...</td>\n",
       "      <td>2006-05-09 11:29:00</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/sport/fodbold/landshol...</td>\n",
       "      <td>[Frankrig, Jesper Olsen, Jesper Olsen, Jesper ...</td>\n",
       "      <td>...</td>\n",
       "      <td>sport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>Negative</td>\n",
       "      <td>101</td>\n",
       "      <td>1688019633</td>\n",
       "      <td>1147174140</td>\n",
       "      <td>540845493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000700</td>\n",
       "      <td>Madonna topløs med heste</td>\n",
       "      <td>47-årige Madonna poserer både topløs og sammen...</td>\n",
       "      <td>2023-06-29 06:20:33</td>\n",
       "      <td>False</td>\n",
       "      <td>Skal du have stillet Madonna-sulten inden konc...</td>\n",
       "      <td>2006-05-04 11:03:12</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/underholdning/udlandke...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>underholdning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>219</td>\n",
       "      <td>1688019633</td>\n",
       "      <td>1146740592</td>\n",
       "      <td>541279041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000840</td>\n",
       "      <td>Otto Brandenburg er død</td>\n",
       "      <td>Sangeren og skuespilleren Otto Brandenburg er ...</td>\n",
       "      <td>2023-06-29 06:20:33</td>\n",
       "      <td>False</td>\n",
       "      <td>'Og lidt for Susanne, Birgitte og Hanne... ' '...</td>\n",
       "      <td>2007-03-01 18:34:00</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/nyheder/samfund/articl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>nyheder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>Negative</td>\n",
       "      <td>10</td>\n",
       "      <td>1688019633</td>\n",
       "      <td>1172774040</td>\n",
       "      <td>515245593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                title  \\\n",
       "0     3000022       Hanks beskyldt for mishandling   \n",
       "1     3000063      Bostrups aske spredt i Furesøen   \n",
       "2     3000613  Jesper Olsen ramt af hjerneblødning   \n",
       "3     3000700             Madonna topløs med heste   \n",
       "4     3000840              Otto Brandenburg er død   \n",
       "\n",
       "                                            subtitle  last_modified_time  \\\n",
       "0  Tom Hanks har angiveligt mishandlet sin afdøde... 2023-06-29 06:20:32   \n",
       "1       Studieværten blev mindet med glad festlighed 2023-06-29 06:20:32   \n",
       "2  Den tidligere danske landsholdsspiller i fodbo... 2023-06-29 06:20:33   \n",
       "3  47-årige Madonna poserer både topløs og sammen... 2023-06-29 06:20:33   \n",
       "4  Sangeren og skuespilleren Otto Brandenburg er ... 2023-06-29 06:20:33   \n",
       "\n",
       "   premium                                               body  \\\n",
       "0    False  Tom Hanks skulle angiveligt have mishandlet si...   \n",
       "1    False  Strålende sensommersol. Jazzede toner. Glas me...   \n",
       "2    False  Jesper Olsen, der er noteret for 43 kampe på d...   \n",
       "3    False  Skal du have stillet Madonna-sulten inden konc...   \n",
       "4    False  'Og lidt for Susanne, Birgitte og Hanne... ' '...   \n",
       "\n",
       "       published_time     article_type  \\\n",
       "0 2006-09-20 09:24:18  article_default   \n",
       "1 2006-09-24 07:45:30  article_default   \n",
       "2 2006-05-09 11:29:00  article_default   \n",
       "3 2006-05-04 11:03:12  article_default   \n",
       "4 2007-03-01 18:34:00  article_default   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://ekstrabladet.dk/underholdning/udlandke...   \n",
       "1  https://ekstrabladet.dk/nyheder/samfund/articl...   \n",
       "2  https://ekstrabladet.dk/sport/fodbold/landshol...   \n",
       "3  https://ekstrabladet.dk/underholdning/udlandke...   \n",
       "4  https://ekstrabladet.dk/nyheder/samfund/articl...   \n",
       "\n",
       "                                        ner_clusters  ...   category_str  \\\n",
       "0                                    [David Gardner]  ...  underholdning   \n",
       "1                                                 []  ...        nyheder   \n",
       "2  [Frankrig, Jesper Olsen, Jesper Olsen, Jesper ...  ...          sport   \n",
       "3                                                 []  ...  underholdning   \n",
       "4                                                 []  ...        nyheder   \n",
       "\n",
       "  total_inviews  total_pageviews total_read_time sentiment_score  \\\n",
       "0           NaN              NaN             NaN          0.9911   \n",
       "1           NaN              NaN             NaN          0.5155   \n",
       "2           NaN              NaN             NaN          0.9876   \n",
       "3           NaN              NaN             NaN          0.8786   \n",
       "4           NaN              NaN             NaN          0.9468   \n",
       "\n",
       "   sentiment_label  subcategory_encoded    mod_time    pub_time time_interval  \n",
       "0         Negative                  219  1688019632  1158744258     529275374  \n",
       "1          Neutral                   10  1688019632  1159083930     528935702  \n",
       "2         Negative                  101  1688019633  1147174140     540845493  \n",
       "3          Neutral                  219  1688019633  1146740592     541279041  \n",
       "4         Negative                   10  1688019633  1172774040     515245593  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting last_modified_time and published_time to milliseconds and calculating the interval\n",
    "\n",
    "# Ensure the timestamps are in datetime format\n",
    "articles_df['last_modified_time'] = pd.to_datetime(articles_df['last_modified_time'])\n",
    "articles_df['published_time'] = pd.to_datetime(articles_df['published_time'])\n",
    "\n",
    "# Calculate mod_time and pub_time in milliseconds\n",
    "articles_df['mod_time'] = articles_df['last_modified_time'].astype('int64') // 10**6  # Convert to milliseconds\n",
    "articles_df['pub_time'] = articles_df['published_time'].astype('int64') // 10**6  # Convert to milliseconds\n",
    "\n",
    "# Calculate the time interval between last_modified_time and published_time in milliseconds\n",
    "articles_df['time_interval'] = articles_df['mod_time'] - articles_df['pub_time']\n",
    "\n",
    "# Display the resulting DataFrame to verify changes\n",
    "articles_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the behavior dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['impression_time', 'read_time', 'article_ids_inview',\n",
      "       'article_ids_clicked', 'user_id', 'is_sso_user', 'is_subscriber',\n",
      "       'session_id', 'next_read_time', 'next_scroll_percentage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(behavior_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Add a feature (articles_num) for the count of in-view articles, and explode article_ids_inview to have one article per row for each impression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lydia\\AppData\\Local\\Temp\\ipykernel_3756\\47074036.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  behavior_df_new['articles_num'] = behavior_df['article_ids_inview'].apply(len)  # Calculate articles_num first\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original row count: 12063890\n",
      "Expected row count after explosion: 133810641\n",
      "Chunk 1: Original rows = 100000, Exploded rows = 1108995\n",
      "Chunk 2: Original rows = 100000, Exploded rows = 1112646\n",
      "Chunk 3: Original rows = 100000, Exploded rows = 1108097\n",
      "Chunk 4: Original rows = 100000, Exploded rows = 1093400\n",
      "Chunk 5: Original rows = 100000, Exploded rows = 1111439\n",
      "Chunk 6: Original rows = 100000, Exploded rows = 1106701\n",
      "Chunk 7: Original rows = 100000, Exploded rows = 1131349\n",
      "Chunk 8: Original rows = 100000, Exploded rows = 1099479\n",
      "Chunk 9: Original rows = 100000, Exploded rows = 1121967\n",
      "Chunk 10: Original rows = 100000, Exploded rows = 1105815\n",
      "Chunk 11: Original rows = 100000, Exploded rows = 1110836\n",
      "Chunk 12: Original rows = 100000, Exploded rows = 1106868\n",
      "Chunk 13: Original rows = 100000, Exploded rows = 1101245\n",
      "Chunk 14: Original rows = 100000, Exploded rows = 1107548\n",
      "Chunk 15: Original rows = 100000, Exploded rows = 1120077\n",
      "Chunk 16: Original rows = 100000, Exploded rows = 1108779\n",
      "Chunk 17: Original rows = 100000, Exploded rows = 1114511\n",
      "Chunk 18: Original rows = 100000, Exploded rows = 1109259\n",
      "Chunk 19: Original rows = 100000, Exploded rows = 1100898\n",
      "Chunk 20: Original rows = 100000, Exploded rows = 1099700\n",
      "Chunk 21: Original rows = 100000, Exploded rows = 1113405\n",
      "Chunk 22: Original rows = 100000, Exploded rows = 1108763\n",
      "Chunk 23: Original rows = 100000, Exploded rows = 1124486\n",
      "Chunk 24: Original rows = 100000, Exploded rows = 1101677\n",
      "Chunk 25: Original rows = 100000, Exploded rows = 1098034\n",
      "Chunk 26: Original rows = 100000, Exploded rows = 1107551\n",
      "Chunk 27: Original rows = 100000, Exploded rows = 1111526\n",
      "Chunk 28: Original rows = 100000, Exploded rows = 1117076\n",
      "Chunk 29: Original rows = 100000, Exploded rows = 1130421\n",
      "Chunk 30: Original rows = 100000, Exploded rows = 1107767\n",
      "Chunk 31: Original rows = 100000, Exploded rows = 1103047\n",
      "Chunk 32: Original rows = 100000, Exploded rows = 1107834\n",
      "Chunk 33: Original rows = 100000, Exploded rows = 1103647\n",
      "Chunk 34: Original rows = 100000, Exploded rows = 1115389\n",
      "Chunk 35: Original rows = 100000, Exploded rows = 1111476\n",
      "Chunk 36: Original rows = 100000, Exploded rows = 1096858\n",
      "Chunk 37: Original rows = 100000, Exploded rows = 1100420\n",
      "Chunk 38: Original rows = 100000, Exploded rows = 1100100\n",
      "Chunk 39: Original rows = 100000, Exploded rows = 1110603\n",
      "Chunk 40: Original rows = 100000, Exploded rows = 1119444\n",
      "Chunk 41: Original rows = 100000, Exploded rows = 1099514\n",
      "Chunk 42: Original rows = 100000, Exploded rows = 1098202\n",
      "Chunk 43: Original rows = 100000, Exploded rows = 1112672\n",
      "Chunk 44: Original rows = 100000, Exploded rows = 1113019\n",
      "Chunk 45: Original rows = 100000, Exploded rows = 1113019\n",
      "Chunk 46: Original rows = 100000, Exploded rows = 1098164\n",
      "Chunk 47: Original rows = 100000, Exploded rows = 1115762\n",
      "Chunk 48: Original rows = 100000, Exploded rows = 1115884\n",
      "Chunk 49: Original rows = 100000, Exploded rows = 1109023\n",
      "Chunk 50: Original rows = 100000, Exploded rows = 1097034\n",
      "Chunk 51: Original rows = 100000, Exploded rows = 1113494\n",
      "Chunk 52: Original rows = 100000, Exploded rows = 1113381\n",
      "Chunk 53: Original rows = 100000, Exploded rows = 1102440\n",
      "Chunk 54: Original rows = 100000, Exploded rows = 1104558\n",
      "Chunk 55: Original rows = 100000, Exploded rows = 1096934\n",
      "Chunk 56: Original rows = 100000, Exploded rows = 1121618\n",
      "Chunk 57: Original rows = 100000, Exploded rows = 1095374\n",
      "Chunk 58: Original rows = 100000, Exploded rows = 1116067\n",
      "Chunk 59: Original rows = 100000, Exploded rows = 1118702\n",
      "Chunk 60: Original rows = 100000, Exploded rows = 1104979\n",
      "Chunk 61: Original rows = 100000, Exploded rows = 1103441\n",
      "Chunk 62: Original rows = 100000, Exploded rows = 1117064\n",
      "Chunk 63: Original rows = 100000, Exploded rows = 1096269\n",
      "Chunk 64: Original rows = 100000, Exploded rows = 1104219\n",
      "Chunk 65: Original rows = 100000, Exploded rows = 1106943\n",
      "Chunk 66: Original rows = 100000, Exploded rows = 1120639\n",
      "Chunk 67: Original rows = 100000, Exploded rows = 1134768\n",
      "Chunk 68: Original rows = 100000, Exploded rows = 1104080\n",
      "Chunk 69: Original rows = 100000, Exploded rows = 1093871\n",
      "Chunk 70: Original rows = 100000, Exploded rows = 1120722\n",
      "Chunk 71: Original rows = 100000, Exploded rows = 1124977\n",
      "Chunk 72: Original rows = 100000, Exploded rows = 1102461\n",
      "Chunk 73: Original rows = 100000, Exploded rows = 1102121\n",
      "Chunk 74: Original rows = 100000, Exploded rows = 1111943\n",
      "Chunk 75: Original rows = 100000, Exploded rows = 1122529\n",
      "Chunk 76: Original rows = 100000, Exploded rows = 1116285\n",
      "Chunk 77: Original rows = 100000, Exploded rows = 1104626\n",
      "Chunk 78: Original rows = 100000, Exploded rows = 1113273\n",
      "Chunk 79: Original rows = 100000, Exploded rows = 1106902\n",
      "Chunk 80: Original rows = 100000, Exploded rows = 1112964\n",
      "Chunk 81: Original rows = 100000, Exploded rows = 1094223\n",
      "Chunk 82: Original rows = 100000, Exploded rows = 1107786\n",
      "Chunk 83: Original rows = 100000, Exploded rows = 1107297\n",
      "Chunk 84: Original rows = 100000, Exploded rows = 1090731\n",
      "Chunk 85: Original rows = 100000, Exploded rows = 1107604\n",
      "Chunk 86: Original rows = 100000, Exploded rows = 1122826\n",
      "Chunk 87: Original rows = 100000, Exploded rows = 1100797\n",
      "Chunk 88: Original rows = 100000, Exploded rows = 1118662\n",
      "Chunk 89: Original rows = 100000, Exploded rows = 1101045\n",
      "Chunk 90: Original rows = 100000, Exploded rows = 1102745\n",
      "Chunk 91: Original rows = 100000, Exploded rows = 1089344\n",
      "Chunk 92: Original rows = 100000, Exploded rows = 1109856\n",
      "Chunk 93: Original rows = 100000, Exploded rows = 1103092\n",
      "Chunk 94: Original rows = 100000, Exploded rows = 1091465\n",
      "Chunk 95: Original rows = 100000, Exploded rows = 1112012\n",
      "Chunk 96: Original rows = 100000, Exploded rows = 1125685\n",
      "Chunk 97: Original rows = 100000, Exploded rows = 1095092\n",
      "Chunk 98: Original rows = 100000, Exploded rows = 1112254\n",
      "Chunk 99: Original rows = 100000, Exploded rows = 1114033\n",
      "Chunk 100: Original rows = 100000, Exploded rows = 1123324\n",
      "Chunk 101: Original rows = 100000, Exploded rows = 1108787\n",
      "Chunk 102: Original rows = 100000, Exploded rows = 1103535\n",
      "Chunk 103: Original rows = 100000, Exploded rows = 1132724\n",
      "Chunk 104: Original rows = 100000, Exploded rows = 1115916\n",
      "Chunk 105: Original rows = 100000, Exploded rows = 1094731\n",
      "Chunk 106: Original rows = 100000, Exploded rows = 1122530\n",
      "Chunk 107: Original rows = 100000, Exploded rows = 1117828\n",
      "Chunk 108: Original rows = 100000, Exploded rows = 1098726\n",
      "Chunk 109: Original rows = 100000, Exploded rows = 1109166\n",
      "Chunk 110: Original rows = 100000, Exploded rows = 1104461\n",
      "Chunk 111: Original rows = 100000, Exploded rows = 1119177\n",
      "Chunk 112: Original rows = 100000, Exploded rows = 1105486\n",
      "Chunk 113: Original rows = 100000, Exploded rows = 1106363\n",
      "Chunk 114: Original rows = 100000, Exploded rows = 1110009\n",
      "Chunk 115: Original rows = 100000, Exploded rows = 1119370\n",
      "Chunk 116: Original rows = 100000, Exploded rows = 1116227\n",
      "Chunk 117: Original rows = 100000, Exploded rows = 1099241\n",
      "Chunk 118: Original rows = 100000, Exploded rows = 1112339\n",
      "Chunk 119: Original rows = 100000, Exploded rows = 1119936\n",
      "Chunk 120: Original rows = 100000, Exploded rows = 1114745\n",
      "Chunk 121: Original rows = 63890, Exploded rows = 700401\n",
      "Total exploded row count after processing all chunks: 133810641\n",
      "All chunks have been processed and saved to disk.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create a new DataFrame with only relevant columns and calculate articles_num for each row\n",
    "behavior_df_new = behavior_df[['impression_time', 'article_ids_inview', 'user_id', 'session_id']]\n",
    "behavior_df_new['articles_num'] = behavior_df['article_ids_inview'].apply(len)  # Calculate articles_num first\n",
    "\n",
    "# Track the original and expected row counts\n",
    "original_row_count = len(behavior_df_new)\n",
    "expected_row_count = behavior_df_new['articles_num'].sum()  # Expected row count after explosion\n",
    "print(f\"Original row count: {original_row_count}\")\n",
    "print(f\"Expected row count after explosion: {expected_row_count}\")\n",
    "\n",
    "# Step 2: Define the chunk size\n",
    "chunk_size = 100000\n",
    "num_chunks = len(behavior_df_new) // chunk_size + 1  # Total number of chunks\n",
    "\n",
    "# Step 3: Process and save each chunk\n",
    "exploded_total_row_count = 0  # Track total rows after explosion\n",
    "for i, start in enumerate(range(0, len(behavior_df_new), chunk_size)):\n",
    "    # Select a chunk of the data\n",
    "    chunk = behavior_df_new.iloc[start:start + chunk_size].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "    \n",
    "    # Explode the chunk to have one article per row\n",
    "    exploded_chunk = chunk.explode('article_ids_inview')\n",
    "    \n",
    "    # Track row count for each exploded chunk\n",
    "    exploded_chunk_row_count = len(exploded_chunk)\n",
    "    exploded_total_row_count += exploded_chunk_row_count\n",
    "    print(f\"Chunk {i+1}: Original rows = {len(chunk)}, Exploded rows = {exploded_chunk_row_count}\")\n",
    "    \n",
    "    # Save the exploded chunk to disk with a unique filename\n",
    "    exploded_chunk.to_parquet(f\"exploded_behavior_data_chunk_{i+1}.parquet\", index=False)\n",
    "    \n",
    "print(f\"Total exploded row count after processing all chunks: {exploded_total_row_count}\")\n",
    "print(\"All chunks have been processed and saved to disk.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All chunks have been merged into 'full_behavior_data.parquet'.\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import glob\n",
    "\n",
    "# Define output file\n",
    "output_file = \"full_behavior_data.parquet\"\n",
    "\n",
    "# Initialize variables\n",
    "first_chunk = True\n",
    "\n",
    "# Initialize the Parquet writer only once, for the first chunk\n",
    "for file in glob.glob(\"exploded_behavior_data_chunk_*.parquet\"):\n",
    "    # Read the chunk\n",
    "    chunk = pq.read_table(file)\n",
    "    \n",
    "    # Write the first chunk to initialize the file with schema\n",
    "    if first_chunk:\n",
    "        # Open the Parquet writer with the schema of the first chunk\n",
    "        writer = pq.ParquetWriter(output_file, chunk.schema)\n",
    "        first_chunk = False\n",
    "    \n",
    "    # Write the current chunk to the output file\n",
    "    writer.write_table(chunk)\n",
    "\n",
    "# Close the writer after all chunks are written\n",
    "writer.close()\n",
    "\n",
    "print(\"All chunks have been merged into 'full_behavior_data.parquet'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133810641"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Read the merged Parquet file to check the number of rows\n",
    "table = pq.read_table(\"full_behavior_data.parquet\")\n",
    "num_rows = table.num_rows\n",
    "num_rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the full_behavior_data.parquet to behavior_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in original behavior_df: 12063890\n",
      "Rows in exploded behavior_df_new: 1114033\n"
     ]
    }
   ],
   "source": [
    "# Check row count before explosion\n",
    "original_rows = len(behavior_df)\n",
    "print(f\"Rows in original behavior_df: {original_rows}\")\n",
    "\n",
    "# Check row count after explosion\n",
    "exploded_rows = len(behavior_df_new)\n",
    "print(f\"Rows in exploded behavior_df_new: {exploded_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with empty lists in 'article_ids_inview': 12063890\n",
      "Rows with NaN in 'article_ids_inview': 0\n"
     ]
    }
   ],
   "source": [
    "# Count rows with empty lists in 'article_ids_inview'\n",
    "empty_lists_count = behavior_df['article_ids_inview'].apply(lambda x: len(x) if isinstance(x, list) else 0).value_counts().get(0, 0)\n",
    "\n",
    "# Count rows with NaN in 'article_ids_inview'\n",
    "nan_count = behavior_df['article_ids_inview'].isna().sum()\n",
    "\n",
    "print(f\"Rows with empty lists in 'article_ids_inview': {empty_lists_count}\")\n",
    "print(f\"Rows with NaN in 'article_ids_inview': {nan_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [9482380, 9775183, 9744403, 9775297, 9774020, ...\n",
      "1         [9774557, 9774516, 9775331, 9775277, 9759966]\n",
      "2     [9759966, 9774557, 9775352, 9746360, 9772601, ...\n",
      "3     [9774580, 9775131, 9775202, 9774789, 9774972, ...\n",
      "4     [9774826, 9775171, 9775076, 9769624, 9775056, ...\n",
      "                            ...                        \n",
      "95    [9767481, 9774840, 9774864, 9775042, 9775323, ...\n",
      "96        [9775371, 9773947, 9775432, 9770028, 9771051]\n",
      "97    [9775361, 9772706, 9770288, 9775419, 9775402, ...\n",
      "98        [9759544, 9773947, 9771051, 9775371, 9774461]\n",
      "99        [9759966, 9775352, 9774557, 9774652, 9775277]\n",
      "Name: article_ids_inview, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Alternatively, print the first 100 rows for a sample view:\n",
    "print(behavior_df['article_ids_inview'].head(100))  # Shows first 100 entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     article_ids_inview  articles_num\n",
      "11209732  [9759966, 9775793, 9770145, 9774461, 9770450]             5\n",
      "2845750   [9777005, 9777112, 9776917, 9777036, 9776916]             5\n",
      "7273666   [9135506, 7865155, 9771995, 9521144, 9552120]             5\n",
      "2845758   [9776897, 9776968, 9776882, 9777007, 9525589]             5\n",
      "2845761   [9777075, 9777164, 9775908, 9777233, 9777043]             5\n",
      "...                                                 ...           ...\n",
      "2845534   [9777164, 9767554, 9777075, 9775908, 9777228]             5\n",
      "2845535   [9777075, 9777043, 9777233, 9777164, 9775908]             5\n",
      "2845537   [9775776, 9775800, 7306652, 9759966, 9775703]             5\n",
      "2845538   [9776918, 9776985, 9777164, 9777043, 9777233]             5\n",
      "11177128  [9774542, 9774789, 9774899, 9774580, 9774972]             5\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step-by-step code to calculate, sort, and display\n",
    "\n",
    "# Calculate the number of articles in each list in 'article_ids_inview'\n",
    "behavior_df['articles_num'] = behavior_df['article_ids_inview'].apply(len)\n",
    "\n",
    "# Sort by 'articles_num' in ascending order\n",
    "sorted_behavior_df = behavior_df.sort_values(by='articles_num')\n",
    "\n",
    "# Display the first 100 rows of sorted results\n",
    "print(sorted_behavior_df[['article_ids_inview', 'articles_num']].head(100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original row count: 12063890\n",
      "Minimum articles_num value: 5\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Verify original row count and the minimum value in articles_num\n",
    "original_row_count = len(behavior_df)\n",
    "min_articles_num = behavior_df['articles_num'].min()\n",
    "print(f\"Original row count: {original_row_count}\")\n",
    "print(f\"Minimum articles_num value: {min_articles_num}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows\n",
    "#num_rows = len(behavior_df_new)\n",
    "#num_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 100 rows of the behavior_df_new DataFrame\n",
    "#behavior_df_new.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#behavior_df_new.rename(columns={'article_ids_inview': 'article_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(behavior_df_new.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create an impr_time that converts impression_time to an integer representation in milliseconds,\n",
    "\n",
    "impr_pub_interval: calculates the difference between the impression and published times, giving the delay bewteem publishing and the user's impression\n",
    "\n",
    "mpr_pub_hour that converts this interval into hours for easier groupin and analysis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract article_id from behavior_df_new ( after exploding article_ids_inview).\n",
    "2. Merge behavior_df_new with articles_df on article_id.\n",
    "3. Calculate impr_time, impr_pub_interval, and impr_pub_hour based on impression_time and published_time from the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'article_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3756\\2225723929.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0marticles_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'published_time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticles_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'published_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Merge behavior_df with articles_df on article_id to bring in published_time information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbehavior_df_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticles_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'article_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'published_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'article_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# 1. Convert impression_time to an integer representation in milliseconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'impr_time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'impression_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int64'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m6\u001b[0m  \u001b[1;31m# Convert from nanoseconds to milliseconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lydia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10801\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10802\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10803\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10805\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m  10806\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10807\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10808\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lydia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lydia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_merge_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lydia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1306\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1310\u001b[1;33m                         \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1311\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m                         \u001b[1;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lydia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1906\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1907\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1910\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1912\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'article_id'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the necessary columns are in datetime format\n",
    "# Convert both 'impression_time' and 'published_time' to datetime if not already done\n",
    "behavior_df_new['impression_time'] = pd.to_datetime(behavior_df_new['impression_time'])\n",
    "articles_df['published_time'] = pd.to_datetime(articles_df['published_time'])\n",
    "\n",
    "\n",
    "# Merge behavior_df with articles_df on article_id to bring in published_time information\n",
    "merged_df = behavior_df_new.merge(articles_df[['article_id', 'published_time']], on='article_id', how='left')\n",
    "\n",
    "# 1. Convert impression_time to an integer representation in milliseconds\n",
    "merged_df['impr_time'] = merged_df['impression_time'].astype('int64') // 10**6  # Convert from nanoseconds to milliseconds\n",
    "\n",
    "# 2. Calculate the delay (in milliseconds) between the impression and the published time\n",
    "merged_df['impr_pub_interval'] = (merged_df['impression_time'] - merged_df['published_time']).dt.total_seconds() * 1000\n",
    "\n",
    "# 3. Convert the impr_pub_interval to hours\n",
    "merged_df['impr_pub_hour'] = merged_df['impr_pub_interval'] / (1000 * 3600)  # Convert milliseconds to hours\n",
    "\n",
    "# Display a sample to verify\n",
    "print(merged_df[['impression_time', 'published_time', 'impr_time', 'impr_pub_interval', 'impr_pub_hour']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_time</th>\n",
       "      <th>article_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>articles_num</th>\n",
       "      <th>published_time</th>\n",
       "      <th>impr_time</th>\n",
       "      <th>impr_pub_interval</th>\n",
       "      <th>impr_pub_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-20 16:28:45</td>\n",
       "      <td>9773278</td>\n",
       "      <td>1155045</td>\n",
       "      <td>27292978</td>\n",
       "      <td>44</td>\n",
       "      <td>2023-05-20 13:53:40</td>\n",
       "      <td>1684600125</td>\n",
       "      <td>9305000.0</td>\n",
       "      <td>2.584722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-20 16:28:45</td>\n",
       "      <td>9773364</td>\n",
       "      <td>1155045</td>\n",
       "      <td>27292978</td>\n",
       "      <td>44</td>\n",
       "      <td>2023-05-20 10:00:09</td>\n",
       "      <td>1684600125</td>\n",
       "      <td>23316000.0</td>\n",
       "      <td>6.476667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-20 16:28:45</td>\n",
       "      <td>9773574</td>\n",
       "      <td>1155045</td>\n",
       "      <td>27292978</td>\n",
       "      <td>44</td>\n",
       "      <td>2023-05-20 13:06:04</td>\n",
       "      <td>1684600125</td>\n",
       "      <td>12161000.0</td>\n",
       "      <td>3.378056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-20 16:28:45</td>\n",
       "      <td>9773744</td>\n",
       "      <td>1155045</td>\n",
       "      <td>27292978</td>\n",
       "      <td>44</td>\n",
       "      <td>2023-05-20 15:13:29</td>\n",
       "      <td>1684600125</td>\n",
       "      <td>4516000.0</td>\n",
       "      <td>1.254444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-20 16:28:45</td>\n",
       "      <td>9767566</td>\n",
       "      <td>1155045</td>\n",
       "      <td>27292978</td>\n",
       "      <td>44</td>\n",
       "      <td>2023-05-20 11:56:18</td>\n",
       "      <td>1684600125</td>\n",
       "      <td>16347000.0</td>\n",
       "      <td>4.540833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      impression_time article_id  user_id  session_id  articles_num  \\\n",
       "0 2023-05-20 16:28:45    9773278  1155045    27292978            44   \n",
       "1 2023-05-20 16:28:45    9773364  1155045    27292978            44   \n",
       "2 2023-05-20 16:28:45    9773574  1155045    27292978            44   \n",
       "3 2023-05-20 16:28:45    9773744  1155045    27292978            44   \n",
       "4 2023-05-20 16:28:45    9767566  1155045    27292978            44   \n",
       "\n",
       "       published_time   impr_time  impr_pub_interval  impr_pub_hour  \n",
       "0 2023-05-20 13:53:40  1684600125          9305000.0       2.584722  \n",
       "1 2023-05-20 10:00:09  1684600125         23316000.0       6.476667  \n",
       "2 2023-05-20 13:06:04  1684600125         12161000.0       3.378056  \n",
       "3 2023-05-20 15:13:29  1684600125          4516000.0       1.254444  \n",
       "4 2023-05-20 11:56:18  1684600125         16347000.0       4.540833  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then hourly impressions count for each article: this loop counts the numbr of impressions for each article by hour intervals up to 24 hours, for each hour i , it filters data where impr_pub_interval is within that hour range .\n",
    "\n",
    " It then groups by article_id to count the impressions and merges these counts back into the behavior data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly impressions by article calculated and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the processed chunks back if not already loaded\n",
    "# You would iterate over each saved chunk file to perform the following\n",
    "hourly_impressions = pd.DataFrame()\n",
    "\n",
    "# Define the hour intervals (1 to 24 hours)\n",
    "for hour in range(1, 25):\n",
    "    # Filter data within the current hour range (i.e., 0 to `hour` hours in milliseconds)\n",
    "    filtered_df = merged_df[(merged_df['impr_pub_interval'] >= (hour - 1) * 3600 * 1000) &\n",
    "                               (merged_df['impr_pub_interval'] < hour * 3600 * 1000)]\n",
    "    \n",
    "    # Group by 'article_id' and count impressions within this hour range\n",
    "    hourly_count = filtered_df.groupby('article_id').size().reset_index(name=f'impressions_hour_{hour}')\n",
    "    \n",
    "    # Merge this hourly count back into the main DataFrame\n",
    "    if hourly_impressions.empty:\n",
    "        hourly_impressions = hourly_count\n",
    "    else:\n",
    "        hourly_impressions = pd.merge(hourly_impressions, hourly_count, on='article_id', how='outer').fillna(0)\n",
    "\n",
    "# Fill any missing counts with zero for clarity\n",
    "hourly_impressions = hourly_impressions.fillna(0)\n",
    "\n",
    "# Save or merge `hourly_impressions` back to your main data as needed\n",
    "hourly_impressions.to_parquet(\"/mnt/data/hourly_impressions_by_article.parquet\", index=False)\n",
    "print(\"Hourly impressions by article calculated and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate impression differences betweenhours: computes the difference in impression counts between consecutive hours, this gives insight into how impression numbers change hour by hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id  impression_diff_hour_2  impression_diff_hour_3  \\\n",
      "0     9735909                   395.0                  -386.0   \n",
      "1     9738729                   -86.0                  -103.0   \n",
      "2     9743870                  -113.0                  -269.0   \n",
      "3     9743874                     0.0                     0.0   \n",
      "4     9744403                  -484.0                    -7.0   \n",
      "\n",
      "   impression_diff_hour_4  impression_diff_hour_5  impression_diff_hour_6  \\\n",
      "0                    84.0                   139.0                  -227.0   \n",
      "1                   107.0                   -30.0                   -77.0   \n",
      "2                   -56.0                     0.0                     0.0   \n",
      "3                     1.0                    -1.0                     0.0   \n",
      "4                     0.0                     0.0                     0.0   \n",
      "\n",
      "   impression_diff_hour_7  impression_diff_hour_8  impression_diff_hour_9  \\\n",
      "0                    -5.0                    34.0                   -12.0   \n",
      "1                   142.0                   -55.0                   -11.0   \n",
      "2                     0.0                     0.0                     0.0   \n",
      "3                     0.0                     0.0                     1.0   \n",
      "4                     0.0                     0.0                     0.0   \n",
      "\n",
      "   impression_diff_hour_10  ...  impression_diff_hour_15  \\\n",
      "0                    -20.0  ...                      0.0   \n",
      "1                     -8.0  ...                      0.0   \n",
      "2                      0.0  ...                      0.0   \n",
      "3                     -1.0  ...                      0.0   \n",
      "4                     21.0  ...                     16.0   \n",
      "\n",
      "   impression_diff_hour_16  impression_diff_hour_17  impression_diff_hour_18  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                     34.0   \n",
      "2                      0.0                      0.0                      1.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                    -16.0                      1.0                     -1.0   \n",
      "\n",
      "   impression_diff_hour_19  impression_diff_hour_20  impression_diff_hour_21  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      6.0                    -40.0                     54.0   \n",
      "2                     -1.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   impression_diff_hour_22  impression_diff_hour_23  impression_diff_hour_24  \n",
      "0                      0.0                      0.0                      0.0  \n",
      "1                    -22.0                     91.0                    -31.0  \n",
      "2                      0.0                      1.0                     -1.0  \n",
      "3                      0.0                      1.0                     -1.0  \n",
      "4                      0.0                      0.0                      1.0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Hourly impression differences calculated and saved.\n"
     ]
    }
   ],
   "source": [
    "# Assuming `hourly_impressions` has columns ['article_id', 'impressions_hour_1', ..., 'impressions_hour_24']\n",
    "# Calculate hourly differences\n",
    "impression_differences = hourly_impressions[['article_id']].copy()  # Start with article_id for merging purposes\n",
    "\n",
    "# Loop through each hour (from hour 2 to 24) and calculate the difference with the previous hour\n",
    "for hour in range(2, 25):\n",
    "    prev_hour = hour - 1\n",
    "    impression_differences[f'impression_diff_hour_{hour}'] = (\n",
    "        hourly_impressions[f'impressions_hour_{hour}'] - hourly_impressions[f'impressions_hour_{prev_hour}']\n",
    "    )\n",
    "\n",
    "# Display a sample of the differences to verify\n",
    "print(impression_differences.head())\n",
    "\n",
    "# Save the impression differences DataFrame if needed\n",
    "impression_differences.to_parquet(\"/mnt/data/impression_differences_by_hour.parquet\", index=False)\n",
    "print(\"Hourly impression differences calculated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'impression_diff_hour_2', 'impression_diff_hour_3',\n",
       "       'impression_diff_hour_4', 'impression_diff_hour_5',\n",
       "       'impression_diff_hour_6', 'impression_diff_hour_7',\n",
       "       'impression_diff_hour_8', 'impression_diff_hour_9',\n",
       "       'impression_diff_hour_10', 'impression_diff_hour_11',\n",
       "       'impression_diff_hour_12', 'impression_diff_hour_13',\n",
       "       'impression_diff_hour_14', 'impression_diff_hour_15',\n",
       "       'impression_diff_hour_16', 'impression_diff_hour_17',\n",
       "       'impression_diff_hour_18', 'impression_diff_hour_19',\n",
       "       'impression_diff_hour_20', 'impression_diff_hour_21',\n",
       "       'impression_diff_hour_22', 'impression_diff_hour_23',\n",
       "       'impression_diff_hour_24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impression_differences.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Hourly Impression Features for Each Article:This part extracts hourly impression features for each article_id.\n",
    "For each hour (i), it renames columns and calculates differences in hourly impressions to create additional features.\n",
    "These features help in understanding how the impression rates for an article change over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id  impressions_hour_1  impressions_hour_2  impression_diff_hour_2  \\\n",
      "0     9735909                 0.0               395.0                   395.0   \n",
      "1     9738729               189.0               103.0                   -86.0   \n",
      "2     9743870               438.0               325.0                  -113.0   \n",
      "3     9743874                 0.0                 0.0                     0.0   \n",
      "4     9744403               491.0                 7.0                  -484.0   \n",
      "\n",
      "   impressions_hour_3  impression_diff_hour_3  impressions_hour_4  \\\n",
      "0                 9.0                  -386.0                93.0   \n",
      "1                 0.0                  -103.0               107.0   \n",
      "2                56.0                  -269.0                 0.0   \n",
      "3                 0.0                     0.0                 1.0   \n",
      "4                 0.0                    -7.0                 0.0   \n",
      "\n",
      "   impression_diff_hour_4  impressions_hour_5  impression_diff_hour_5  ...  \\\n",
      "0                    84.0               232.0                   139.0  ...   \n",
      "1                   107.0                77.0                   -30.0  ...   \n",
      "2                   -56.0                 0.0                     0.0  ...   \n",
      "3                     1.0                 0.0                    -1.0  ...   \n",
      "4                     0.0                 0.0                     0.0  ...   \n",
      "\n",
      "   impressions_hour_20  impression_diff_hour_20  impressions_hour_21  \\\n",
      "0                  0.0                      0.0                  0.0   \n",
      "1                  0.0                    -40.0                 54.0   \n",
      "2                  0.0                      0.0                  0.0   \n",
      "3                  0.0                      0.0                  0.0   \n",
      "4                  0.0                      0.0                  0.0   \n",
      "\n",
      "   impression_diff_hour_21  impressions_hour_22  impression_diff_hour_22  \\\n",
      "0                      0.0                  0.0                      0.0   \n",
      "1                     54.0                 32.0                    -22.0   \n",
      "2                      0.0                  0.0                      0.0   \n",
      "3                      0.0                  0.0                      0.0   \n",
      "4                      0.0                  0.0                      0.0   \n",
      "\n",
      "   impressions_hour_23  impression_diff_hour_23  impressions_hour_24  \\\n",
      "0                  0.0                      0.0                  0.0   \n",
      "1                123.0                     91.0                 92.0   \n",
      "2                  1.0                      1.0                  0.0   \n",
      "3                  1.0                      1.0                  0.0   \n",
      "4                  0.0                      0.0                  1.0   \n",
      "\n",
      "   impression_diff_hour_24  \n",
      "0                      0.0  \n",
      "1                    -31.0  \n",
      "2                     -1.0  \n",
      "3                     -1.0  \n",
      "4                      1.0  \n",
      "\n",
      "[5 rows x 48 columns]\n",
      "Hourly impression features for each article calculated and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `hourly_impressions` has columns like ['article_id', 'impressions_hour_1', ..., 'impressions_hour_24']\n",
    "\n",
    "# Initialize a new DataFrame to store hourly features for each article\n",
    "hourly_features = hourly_impressions[['article_id']].copy()\n",
    "\n",
    "# Loop through each hour and calculate impression counts and differences\n",
    "for hour in range(1, 25):\n",
    "    # Rename the impression count column for clarity\n",
    "    hourly_features[f'impressions_hour_{hour}'] = hourly_impressions[f'impressions_hour_{hour}']\n",
    "\n",
    "    # Calculate the hourly impression difference (for hours 2 and onward)\n",
    "    if hour > 1:\n",
    "        hourly_features[f'impression_diff_hour_{hour}'] = (\n",
    "            hourly_impressions[f'impressions_hour_{hour}'] - hourly_impressions[f'impressions_hour_{hour - 1}']\n",
    "        )\n",
    "\n",
    "# Display the hourly features DataFrame to verify\n",
    "print(hourly_features.head())\n",
    "\n",
    "# Save the DataFrame if needed\n",
    "hourly_features.to_parquet(\"/mnt/data/hourly_impression_features_by_article.parquet\", index=False)\n",
    "print(\"Hourly impression features for each article calculated and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate by Hour and Calculate Averages\n",
    "Groups impressions by article_id and article_impr_hour, counting impressions per hour per article.\n",
    "This helps to capture the popularity and demand for an article over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
