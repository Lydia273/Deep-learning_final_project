{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAdditiveAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements multi-head additive attention for user encoding,\n",
    "    strictly following the provided formulas.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - embed_dim: Dimensionality of the input embeddings (news representations).\n",
    "        - num_heads: Number of attention heads.\n",
    "        \"\"\"\n",
    "        super(MultiHeadAdditiveAttention, self).__init__()\n",
    "        assert embed_dim % num_heads == 0, \"embed_dim must be divisible by num_heads\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        # Parameters for each head\n",
    "        self.Q_n = nn.ParameterList([nn.Parameter(torch.randn(self.head_dim, self.head_dim)) for _ in range(num_heads)])\n",
    "        self.V_n = nn.ParameterList([nn.Parameter(torch.randn(self.head_dim, self.head_dim)) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, news_embeddings):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - news_embeddings: Tensor of shape (batch_size, num_news, embed_dim),\n",
    "                           representing the news representations.\n",
    "\n",
    "        Returns:\n",
    "        - enhanced_news_embeddings: Tensor of shape (batch_size, num_news, embed_dim),\n",
    "                                    enhanced news representations.\n",
    "        - attention_weights: List of tensors of shape (batch_size, num_news, num_news) per head,\n",
    "                             attention weights for each head.\n",
    "        \"\"\"\n",
    "        batch_size, num_news, embed_dim = news_embeddings.size()\n",
    "\n",
    "        # Split embeddings for each head\n",
    "        news_per_head = news_embeddings.view(batch_size, num_news, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        all_head_outputs = []\n",
    "        all_attention_weights = []\n",
    "\n",
    "        for h in range(self.num_heads):\n",
    "            Q_n = self.Q_n[h]\n",
    "            scores = torch.einsum('bnd,dk,bmk->bnm', news_per_head[:, h, :, :], Q_n, news_per_head[:, h, :, :])\n",
    "            attention_weights = F.softmax(scores, dim=-1)\n",
    "            V_n = self.V_n[h]\n",
    "            head_output = torch.einsum('bnm,bmd,dk->bnd', attention_weights, news_per_head[:, h, :, :], V_n)\n",
    "\n",
    "            all_head_outputs.append(head_output)\n",
    "            all_attention_weights.append(attention_weights)\n",
    "\n",
    "        concat_output = torch.cat(all_head_outputs, dim=-1)\n",
    "        return concat_output, all_attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test configuration\n",
    "batch_size = 4\n",
    "num_news = 10\n",
    "embed_dim = 300\n",
    "num_heads = 10\n",
    "\n",
    "# Simulated input\n",
    "news_embeddings = torch.randn(batch_size, num_news, embed_dim)\n",
    "\n",
    "# Initialize and test the module\n",
    "attention_layer = MultiHeadAdditiveAttention(embed_dim=embed_dim, num_heads=num_heads)\n",
    "enhanced_news_embeddings, attention_weights = attention_layer(news_embeddings)\n",
    "\n",
    "# Validate outputs\n",
    "print(\"Enhanced News Embeddings Shape:\", enhanced_news_embeddings.shape)  # Expected: (batch_size, num_news, embed_dim)\n",
    "print(\"Attention Weights Shape (per head):\", attention_weights[0].shape)  # Expected: (batch_size, num_news, num_news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class UserAdditiveAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements additive attention for user encoding based on the provided formulas.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - embed_dim: Dimensionality of the input embeddings (news representations).\n",
    "        \"\"\"\n",
    "        super(UserAdditiveAttention, self).__init__()\n",
    "        self.V_n = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "        self.v_n = nn.Parameter(torch.zeros(embed_dim))\n",
    "        self.q_n = nn.Parameter(torch.randn(embed_dim))\n",
    "\n",
    "    def forward(self, news_embeddings):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - news_embeddings: Tensor of shape (batch_size, num_news, embed_dim),\n",
    "                           representing the news representations.\n",
    "\n",
    "        Returns:\n",
    "        - user_representation: Tensor of shape (batch_size, embed_dim),\n",
    "                               the final user representation.\n",
    "        - attention_weights: Tensor of shape (batch_size, num_news),\n",
    "                             attention weights for the news articles.\n",
    "        \"\"\"\n",
    "        transformed_news = self.V_n(news_embeddings)\n",
    "        scores = torch.tanh(transformed_news + self.v_n)\n",
    "        scores = torch.einsum('bnd,d->bn', scores, self.q_n)\n",
    "        attention_weights = F.softmax(scores, dim=1)\n",
    "        user_representation = torch.einsum('bn,bnd->bd', attention_weights, news_embeddings)\n",
    "        return user_representation, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 16\n",
    "num_news = 10  # Number of news articles browsed by each user\n",
    "embed_dim = 300\n",
    "\n",
    "# Dummy input\n",
    "news_embeddings = torch.rand(batch_size, num_news, embed_dim)  # Random news embeddings\n",
    "\n",
    "# Initialize the UserAdditiveAttention layer\n",
    "user_attention_layer = UserAdditiveAttention(embed_dim=embed_dim)\n",
    "\n",
    "# Forward pass\n",
    "user_representation, attention_weights = user_attention_layer(news_embeddings)\n",
    "\n",
    "# Output shapes\n",
    "print(\"User representation shape:\", user_representation.shape)  # Expected: (16, 300)\n",
    "print(\"Attention weights shape:\", attention_weights.shape)  # Expected: (16, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Combines MultiHeadAdditiveAttention and UserAdditiveAttention\n",
    "    to encode user representations based on news embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - embed_dim: Dimensionality of the input embeddings (news representations).\n",
    "        - num_heads: Number of attention heads in the MultiHeadAdditiveAttention layer.\n",
    "        \"\"\"\n",
    "        super(UserEncoder, self).__init__()\n",
    "        self.multi_head_attention = MultiHeadAdditiveAttention(embed_dim=embed_dim, num_heads=num_heads)\n",
    "        self.user_attention = UserAdditiveAttention(embed_dim=embed_dim)\n",
    "\n",
    "    def forward(self, news_embeddings):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - news_embeddings: Tensor of shape (batch_size, num_news, embed_dim),\n",
    "                           representing the news representations.\n",
    "\n",
    "        Returns:\n",
    "        - user_representation: Tensor of shape (batch_size, embed_dim),\n",
    "                               the final user representation.\n",
    "        - attention_weights: Dictionary containing:\n",
    "            - 'multi_head_attention': List of tensors of shape (batch_size, num_news, num_news) per head,\n",
    "                                      attention weights for each head from the MultiHeadAdditiveAttention layer.\n",
    "            - 'user_attention': Tensor of shape (batch_size, num_news),\n",
    "                                attention weights for the news articles from the UserAdditiveAttention layer.\n",
    "        \"\"\"\n",
    "        enhanced_news_embeddings, multi_head_attention_weights = self.multi_head_attention(news_embeddings)\n",
    "        user_representation, user_attention_weights = self.user_attention(enhanced_news_embeddings)\n",
    "\n",
    "        attention_weights = {\n",
    "            'multi_head_attention': multi_head_attention_weights,\n",
    "            'user_attention': user_attention_weights\n",
    "        }\n",
    "        return user_representation, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define parameters\n",
    "embed_dim = 300    # Embedding dimension\n",
    "num_heads = 10     # Number of attention heads\n",
    "batch_size = 4     # Number of users in the batch\n",
    "num_articles = 5   # Number of articles browsed by each user\n",
    "\n",
    "# Simulate input data (news representations from News Encoder)\n",
    "user_input = torch.randn(batch_size, num_articles, embed_dim)  # Random tensor for simulation\n",
    "\n",
    "# Initialize the UserEncoder\n",
    "user_encoder = UserEncoder(embed_dim=embed_dim, num_heads=num_heads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 16\n",
    "num_news = 10  # Number of news articles browsed by each user\n",
    "embed_dim = 300\n",
    "num_heads = 10\n",
    "\n",
    "# Dummy input\n",
    "news_embeddings = torch.rand(batch_size, num_news, embed_dim)  # Random news embeddings\n",
    "\n",
    "# Initialize the UserEncoder\n",
    "user_encoder = UserEncoder(embed_dim=embed_dim, num_heads=num_heads)\n",
    "\n",
    "# Forward pass\n",
    "user_representation, attention_weights = user_encoder(news_embeddings)\n",
    "\n",
    "# Output shapes\n",
    "print(\"User representation shape:\", user_representation.shape)  # Expected: (16, 300)\n",
    "print(\"Multi-head attention weights shape (head 0):\", attention_weights['multi_head_attention'][0].shape)  # Expected: (16, 10, 10)\n",
    "print(\"User attention weights shape:\", attention_weights['user_attention'].shape)  # Expected: (16, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests\n",
    "Test the Execution of every aspect of the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_user_encoder_initialization(user_encoder):\n",
    "    assert user_encoder is not None, \"UserEncoder initialization failed.\"\n",
    "    print(\"UserEncoder initialization test passed.\")\n",
    "\n",
    "def test_user_encoder_forward(user_encoder, news_embeddings):\n",
    "    user_representation, attention_weights = user_encoder(news_embeddings)\n",
    "    assert user_representation.shape == (16, 64), \"User representation shape mismatch!\"\n",
    "    assert 'multi_head_attention' in attention_weights, \"Missing multi_head_attention key!\"\n",
    "    assert 'user_attention' in attention_weights, \"Missing user_attention key!\"\n",
    "    print(\"UserEncoder forward pass test passed.\")\n",
    "\n",
    "def test_multi_head_attention(multi_head_attention, news_embeddings):\n",
    "    enhanced_news_embeddings, attention_weights = multi_head_attention(news_embeddings)\n",
    "    assert enhanced_news_embeddings.shape == (16, 10, 64), \"Multi-head attention output shape mismatch!\"\n",
    "    print(\"MultiHeadAdditiveAttention test passed.\")\n",
    "\n",
    "def test_user_additive_attention(user_attention, news_embeddings):\n",
    "    user_representation, attention_weights = user_attention(news_embeddings)\n",
    "    assert user_representation.shape == (16, 64), \"User representation shape mismatch!\"\n",
    "    assert attention_weights.shape == (16, 10), \"Attention weights shape mismatch!\"\n",
    "    print(\"UserAdditiveAttention test passed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize test inputs\n",
    "    batch_size = 16\n",
    "    num_news = 10\n",
    "    embed_dim = 64\n",
    "    num_heads = 4\n",
    "\n",
    "    # Create random news embeddings\n",
    "    news_embeddings = torch.randn(batch_size, num_news, embed_dim)\n",
    "    print(\"News embeddings initialized:\", news_embeddings.shape)\n",
    "\n",
    "    # Initialize UserEncoder\n",
    "    user_encoder = UserEncoder(embed_dim=embed_dim, num_heads=num_heads)\n",
    "    print(\"UserEncoder initialized.\")\n",
    "\n",
    "    # Test: Initialization\n",
    "    test_user_encoder_initialization(user_encoder)\n",
    "\n",
    "    # Test: Forward pass\n",
    "    test_user_encoder_forward(user_encoder, news_embeddings)\n",
    "\n",
    "    # Test: MultiHeadAdditiveAttention\n",
    "    multi_head_attention = MultiHeadAdditiveAttention(embed_dim=embed_dim, num_heads=num_heads)\n",
    "    test_multi_head_attention(multi_head_attention, news_embeddings)\n",
    "\n",
    "    # Test: UserAdditiveAttention\n",
    "    user_attention = UserAdditiveAttention(embed_dim=embed_dim)\n",
    "    test_user_additive_attention(user_attention, news_embeddings)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems to be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Debugging Script\n",
    "\n",
    "import torch\n",
    "\n",
    "# Define Parameters\n",
    "batch_size = 4    # Number of users in the batch\n",
    "num_articles = 5  # Number of articles browsed per user\n",
    "embed_dim = 300   # Embedding dimension (output from News Encoder)\n",
    "num_heads = 10    # Number of attention heads\n",
    "\n",
    "# Generate Input Data\n",
    "user_input = torch.randn(batch_size, num_articles, embed_dim)\n",
    "print(\"User Input Shape:\", user_input.shape)\n",
    "\n",
    "# Initialize the User Encoder\n",
    "try:\n",
    "    user_encoder = UserEncoder(embed_dim=embed_dim, num_heads=num_heads)\n",
    "    print(\"UserEncoder initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during UserEncoder initialization: {e}\")\n",
    "\n",
    "# Forward Pass\n",
    "try:\n",
    "    user_representation, attention_weights = user_encoder(user_input)\n",
    "    print(\"Forward pass completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during forward pass: {e}\")\n",
    "\n",
    "# Validate Output Shapes\n",
    "try:\n",
    "    print(\"User Representation Shape:\", user_representation.shape)  # Expected: (batch_size, embed_dim)\n",
    "    print(\"Attention Weights Shape:\", attention_weights.shape)      # Expected: (batch_size, num_articles)\n",
    "except Exception as e:\n",
    "    print(f\"Error validating output shapes: {e}\")\n",
    "\n",
    "# Inspect Attention Weights for the First User\n",
    "try:\n",
    "    print(\"\\nAttention Weights for User 1:\\n\", attention_weights[0].detach().numpy())  # Shape: (num_articles)\n",
    "except Exception as e:\n",
    "    print(f\"Error inspecting attention weights: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
